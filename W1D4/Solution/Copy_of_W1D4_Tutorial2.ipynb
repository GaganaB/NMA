{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "name": "Copy of W1D4_Tutorial2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0w40vlVtTyJ"
      },
      "source": [
        "# Neuromatch Academy: Week 1, Day 4, Tutorial 2\n",
        "# Machine Learning: Classifiers and regularizers\n",
        "\n",
        "__Content creators:__ Pierre-Etienne H. Fiquet, Ari Benjamin, Jakob Macke\n",
        "\n",
        "__Content reviewers:__ Davide Valeriani, Alish Dipani, Michael Waskom\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjHrfpX3tTyK"
      },
      "source": [
        "This is part 2 of a 2-part series about Generalized Linear Models (GLMs), which are a fundamental framework for supervised learning. In part 1, we learned about and implemented GLMs. In this tutorial, weâ€™ll implement logistic regression, a special case of GLMs used to model binary outcomes.\n",
        "Oftentimes the variable you would like to predict takes only one of two possible values. Left or right? Awake or asleep? Car or bus? In this tutorial, we will decode a mouse's left/right decisions from spike train data. Our objectives are to:\n",
        "1.\tLearn about logistic regression, how it is derived within the GLM theory, and how it is implemented in scikit-learn\n",
        "2.\tApply logistic regression to decode choies from neural responses\n",
        "3.\tLearn about regularization, including the different approaches and the influence of hyperparameters\n",
        "\n",
        "---\n",
        "We would like to acknowledge [Steinmetz _et al._ (2019)](https://www.nature.com/articles/s41586-019-1787-x) for sharing their data, a subset of which is used here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7darjo83tTyK"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "yiOm0yvCtTyL"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dIPkg6SutTyL"
      },
      "source": [
        "#@title Figure settings\n",
        "import ipywidgets as widgets\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGIHnj-6tTyM"
      },
      "source": [
        "#@title Helper functions\n",
        "\n",
        "def plot_weights(models, sharey=True):\n",
        "  \"\"\"Draw a stem plot of weights for each model in models dict.\"\"\"\n",
        "  n = len(models)\n",
        "  f = plt.figure(figsize=(10, 2.5 * n))\n",
        "  axs = f.subplots(n, sharex=True, sharey=sharey)\n",
        "  axs = np.atleast_1d(axs)\n",
        "\n",
        "  for ax, (title, model) in zip(axs, models.items()):\n",
        "\n",
        "    ax.margins(x=.02)\n",
        "    stem = ax.stem(model.coef_.squeeze(), use_line_collection=True)\n",
        "    stem[0].set_marker(\".\")\n",
        "    stem[0].set_color(\".2\")\n",
        "    stem[1].set_linewidths(.5)\n",
        "    stem[1].set_color(\".2\")\n",
        "    stem[2].set_visible(False)\n",
        "    ax.axhline(0, color=\"C3\", lw=3)\n",
        "    ax.set(ylabel=\"Weight\", title=title)\n",
        "  ax.set(xlabel=\"Neuron (a.k.a. feature)\")\n",
        "  f.tight_layout()\n",
        "\n",
        "\n",
        "def plot_function(f, name, var, points=(-10, 10)):\n",
        "    \"\"\"Evaluate f() on linear space between points and plot.\n",
        "\n",
        "    Args:\n",
        "      f (callable): function that maps scalar -> scalar\n",
        "      name (string): Function name for axis labels\n",
        "      var (string): Variable name for axis labels.\n",
        "      points (tuple): Args for np.linspace to create eval grid.\n",
        "    \"\"\"\n",
        "    x = np.linspace(*points)\n",
        "    ax = plt.figure().subplots()\n",
        "    ax.plot(x, f(x))\n",
        "    ax.set(\n",
        "      xlabel=f'${var}$',\n",
        "      ylabel=f'${name}({var})$'\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_model_selection(C_values, accuracies):\n",
        "  \"\"\"Plot the accuracy curve over log-spaced C values.\"\"\"\n",
        "  ax = plt.figure().subplots()\n",
        "  ax.set_xscale(\"log\")\n",
        "  ax.plot(C_values, accuracies, marker=\"o\")\n",
        "  best_C = C_values[np.argmax(accuracies)]\n",
        "  ax.set(\n",
        "      xticks=C_values,\n",
        "      xlabel=\"$C$\",\n",
        "      ylabel=\"Cross-validated accuracy\",\n",
        "      title=f\"Best C: {best_C:1g} ({np.max(accuracies):.2%})\",\n",
        "  )\n",
        "\n",
        "def plot_non_zero_coefs(C_values, non_zero_l1, n_voxels):\n",
        "  \"\"\"Plot the accuracy curve over log-spaced C values.\"\"\"\n",
        "  ax = plt.figure().subplots()\n",
        "  ax.set_xscale(\"log\")\n",
        "  ax.plot(C_values, non_zero_l1, marker=\"o\")\n",
        "  ax.set(\n",
        "    xticks=C_values,\n",
        "    xlabel=\"$C$\",\n",
        "    ylabel=\"Number of non-zero coefficients\",\n",
        "  )\n",
        "  ax.axhline(n_voxels, color=\".1\", linestyle=\":\")\n",
        "  ax.annotate(\"Total\\n# Neurons\", (C_values[0], n_voxels * .98), va=\"top\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvsLmFlputgz"
      },
      "source": [
        "# Discussion of Helper functions:\n",
        "\n",
        "*plot_weights*:\n",
        "stem plot for every model where yaxis is the weight and xaxis is the neuron aka feature.\n",
        "\n",
        "*plot_function*:\n",
        "Evaluate scalar to scalar mapping function on linear space between points and plot\n",
        "where xaxis = variable name for axis labels and yaxis = function name for axis labels.\n",
        "\n",
        "*plot_model_selection*:\n",
        "plot cross validated accuracy (yaxis) over log-spaced c values (xaxis) in order to find best c/ max accuracy. \n",
        "\n",
        "*plot_non_zero_coefs*:\n",
        "Plot the accuracy curve/ number of non 0 coefficients (yaxis) over log-spaced C values (xaxis) to return the top value of all neurons.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Ako2hW65tTyM"
      },
      "source": [
        "#@title Data retrieval and loading\n",
        "import os\n",
        "import requests\n",
        "import hashlib\n",
        "\n",
        "url = \"https://osf.io/r9gh8/download\"\n",
        "fname = \"W1D4_steinmetz_data.npz\"\n",
        "expected_md5 = \"d19716354fed0981267456b80db07ea8\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    elif hashlib.md5(r.content).hexdigest() != expected_md5:\n",
        "      print(\"!!! Data download appears corrupted !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n",
        "\n",
        "def load_steinmetz_data(data_fname=fname):\n",
        "\n",
        "  with np.load(data_fname) as dobj:\n",
        "    data = dict(**dobj)\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zB7iUdytTyN"
      },
      "source": [
        "---\n",
        "\n",
        "#Section 1: Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-sCVub6btTyN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "4ed0cc95-3f93-4a1c-dc00-4ecfe3567fa3"
      },
      "source": [
        "#@title Video 1: Logistic regression\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"qfXFrUnLU0o\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video available at https://youtube.com/watch?v=qfXFrUnLU0o\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://www.youtube.com/embed/qfXFrUnLU0o?fs=1\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f4cdbecf6a0>"
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWgtV7ykwaPD"
      },
      "source": [
        "# Summary of Video 1:\n",
        "\n",
        "- explore another example of GLM which is called logistic regression. \n",
        "\n",
        "In the previous tutorial, we introduced how to use Poisson GLM to encode neural spike trains from stimuli. The nonlinear function is exponential function and the noise distribution is Poisson. \n",
        "\n",
        "- another instantiation of GLM for the purpose of decoding a binary decision of an animal from spike train data. the input x is now the discrete spike count and generates binary decision variable y. \n",
        "\n",
        "- An encoding model usually attempts to predict brain responses based on the presented stimuli. Well, the decoding model attempts to predict external experimental variables such as behavior, decision and accession based purely on neural signals in the brain. \n",
        "\n",
        "Here we have an example binary decision data set. The input is the linear predictor theta multiplying x and output is the probability of y is equal to 1 or 0. If f is still a linear function, then the black line here would be the best of fit linear curve or linear line. But they actually follow a sigmoid shaped curve. Thus we have the intuition to define f to be a sigmoid function, sigma here, which is a squashing function. \n",
        "\n",
        "distribution of the observation noise: Bernoulli distribution to generate a binary value with some input probability value. \n",
        "Think of a simple single coin flip experiment. Why is a binary random variable representing the outcome of the flip? And the head shows up with probability p and the tail shows up with probability (1 minus p). Then the probability of y is written as this form- is equal to p when y is 1, and is equal to (1 minus p) when y is 0.\n",
        "\n",
        "Thus for all data points, the density function is the product of the probability density for each data point Which has this final expression and therefore, we could finally assign Bernoulli as the noise distribution. We call it Bernoulli GLM. \n",
        "\n",
        "Given the decoding distribution, we could write down the log likelihood for Bernoulli GLM but it doesn't give us closed form solution for theta neither and we need optimization to feed the model similar to Poisson GLM. Finally, this model is also referred to as logistic regression. It's closely related to linear model but with the sigmoid function and works only for discrete outcomes due to the Bernoulli noise distribution. \n",
        "\n",
        "This specific filter tells us that the first chunk of spikes positively correlated to the behavior while the later chunk of the spikes negatively correlated to the behavior. The spike counts around the peak and the valley have the strongest impact. \n",
        "\n",
        "Here, we show a comparison of the three GLMs \n",
        "\n",
        "linear Gaussian model. The output type is real value, the likelihood is Gaussian, and the mean of the Gaussian is just a linear predictor without nonlinear mapping function, f. \n",
        "\n",
        "Poisson GLM. The type of the model is discrete count. We use it for fitting the spike count data. The likelihood is Poisson and the spike rate, lambda, is exponential of the linear predictor. \n",
        "\n",
        "Bernoulli GLM, which is usually called as logistic regression. The output type is binary. It's used for a binary decision prediction task. The likelihood is Bernoulli and the probability of this Bernoulli is sigmoid over the linear predictor. \n",
        "\n",
        "In the following notebook, you will inspect the sigmoid function and use Scikit-learn to fit the logistic regression model to a simulated decision making data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOIAJxc7tTyO"
      },
      "source": [
        "Logistic Regression is a binary classification model. It is a GLM with a *logistic* link function and a *Bernoulli* (i.e. coinflip) noise model.\n",
        "\n",
        "Like in the last notebook, logistic regression invokes a standard procedure:\n",
        "\n",
        "1.   Define a *model* of how inputs relate to outputs.\n",
        "2.   Adjust the parameters to maximize (log) probability of your data given your model\n",
        "\n",
        "## Section 1.1: The logistic regression model\n",
        "\n",
        "The fundamental input/output equation of logistic regression is:\n",
        "\n",
        "\n",
        "$$ \\hat{y} \\equiv p(y=1|x,\\theta) = \\sigma(\\theta^Tx)$$\n",
        "\n",
        "Note that we interpret the output of logistic regression, $\\hat{y}$, as the **probability that y = 1** given inputs $x$ and parameters $\\theta$.\n",
        "\n",
        "Here $\\sigma()$ is a \"squashing\" function called the **sigmoid function** or **logistic function**. Its output is in the range $0 \\leq y \\leq 1$. It looks like this:\n",
        "\n",
        "$$\\sigma(z) = \\frac{1}{1 + \\textrm{exp}(-z)}$$\n",
        "\n",
        "Recall that $z = \\theta^T x$. The parameters decide whether $\\theta^T x$ will be very negative, in which case $\\sigma(\\theta^T x)\\approx 0$, or very positive, meaning  $\\sigma(\\theta^T x)\\approx 1$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCD7KvJntTyP"
      },
      "source": [
        "### Exercise 1: implement the sigmoid function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "NdoH9o0itTyP"
      },
      "source": [
        "def sigmoid(z):\n",
        "  \"\"\"Return the logistic transform of z.\"\"\"\n",
        "  ##############################################################################\n",
        "  # TODO for students: Fill in the missing code (...) and remove the error\n",
        "  raise NotImplementedError(\"Student excercise: implement the sigmoid function\")\n",
        "  ##############################################################################\n",
        "  return ...\n",
        "\n",
        "# Uncomment to test your sigmoid function\n",
        "# plot_function(sigmoid, \"\\sigma\", \"z\", (-10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gMYvjkBtTyQ"
      },
      "source": [
        "# to_remove solution\n",
        "def sigmoid(z):\n",
        "  \"\"\"Return the logistic transform of z.\"\"\"\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "with plt.xkcd():\n",
        "  plot_function(sigmoid, \"\\sigma\", \"z\", (-10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n6H4FSttTyQ"
      },
      "source": [
        "## Section 1.2: Using scikit-learn\n",
        "\n",
        "Unlike the previous notebook, we're not going to write the code that implements all of the Logistic Regression model itself. Instead, we're going to use the implementation in [scikit-learn](https://scikit-learn.org/stable/), a very popular library for Machine Learning.\n",
        "\n",
        "The goal of this next section is to introduce `scikit-learn` classifiers and understand how to apply it to real neural data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7_6zf94tTyQ"
      },
      "source": [
        "#Section 2: Decoding neural data with logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI3dVaomtTyQ"
      },
      "source": [
        "## Section 2.1: Setting up the data\n",
        "\n",
        "In this notebook we'll use the Steinmetz dataset that you have seen previously. Recall that this dataset includes recordings of neurons as mice perform a decision task. \n",
        "\n",
        "Mice had the task of turning a wheel to indicate whether they perceived a Gabor stimulus to the left, to the right, or not at all. Neuropixel probes measured spikes across the cortex. Check out the following task schematic from the BiorXiv preprint:\n",
        "\n",
        "<img src='http://kordinglab.com/images/others/steinmetz-task.png' width= '200'/>\n",
        "\n",
        "Today we're going to **decode the decision from neural data** using Logistic Regression. We will only consider trials where the mouse chose \"Left\" or \"Right\" and ignore NoGo trials.\n",
        "\n",
        "### Data format\n",
        "\n",
        "In the hidden `Data retrieval and loading` cell, there is a function that loads the data:\n",
        "\n",
        "- `spikes`: an array of normalized spike rates with shape `(n_trials, n_neurons)`\n",
        "- `choices`: a vector of 0s and 1s, indicating the animal's behavioral response, with length `n_trials`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gi3zuaQtTyR"
      },
      "source": [
        "data = load_steinmetz_data()\n",
        "for key, val in data.items():\n",
        "  print(key, val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdoVT6T-tTyR"
      },
      "source": [
        "As with the GLMs you've seen in the previous tutorial (Linear and Poisson Regression), we will need two data structures:\n",
        "\n",
        "- an `X` matrix with shape `(n_samples, n_features)`\n",
        "- a `y` vector with length `n_samples`.\n",
        "\n",
        "In the previous notebook, `y` corresponded to the neural data, and `X` corresponded to something about the experiment. Here, we are going to invert those relationships. That's what makes this a *decoding* model: we are going to predict behavior (`y`) from the neural responses (`X`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJMvVmZRtTyR"
      },
      "source": [
        "y = data[\"choices\"]\n",
        "X = data[\"spikes\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx3U1kFItTyS"
      },
      "source": [
        "## Section 2.2: Fitting the model\n",
        "\n",
        "Using a Logistic Regression model within `scikit-learn` is very simple. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z04KM2kdtTyS"
      },
      "source": [
        "# First define the model\n",
        "log_reg = LogisticRegression(penalty=\"none\")\n",
        "\n",
        "#Then fit it to data\n",
        "log_reg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAs7hpZmtTyS"
      },
      "source": [
        "There's two steps here:\n",
        "\n",
        "- We *initialized* the model with a hyperparameter, telling it what penalty to use (we'll focus on this in the second part of the notebook)\n",
        "- We *fit* the model by passing it the `X` and `y` objects.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sPsUpBWtTyT"
      },
      "source": [
        "## Section 2.3: Classifying the training data\n",
        "\n",
        "Fitting the model performs maximum likelihood optimization, learning a set of *feature weights*. We can use those learned weights to *classify* new data, or predict the labels for each sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jcnXR-itTyT"
      },
      "source": [
        "y_pred = log_reg.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyquYkQptTyU"
      },
      "source": [
        "## Section 2.4: Evaluating the model\n",
        "\n",
        "Now we need to evaluate the model's predictions. We'll do that with an *accuracy* score. The accuracy of the classifier is the proportion of trials where the predicted label matches the true label.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moC21bd1tTyU"
      },
      "source": [
        "### Exercise 2: classifier accuracy\n",
        "\n",
        "For the first exercise, implement a function to evaluate a classifier using the accuracy score. Use it to get the accuracy of the classifier on the *training* data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT2486LutTyU"
      },
      "source": [
        "def compute_accuracy(X, y, model):\n",
        "  \"\"\"Compute accuracy of classifier predictions.\n",
        "\n",
        "  Args:\n",
        "    X (2D array): Data matrix\n",
        "    y (1D array): Label vector\n",
        "    model (sklearn estimator): Classifier with trained weights.\n",
        "\n",
        "  Returns:\n",
        "    accuracy (float): Proportion of correct predictions.\n",
        "  \"\"\"\n",
        "  #############################################################################\n",
        "  # TODO Complete the function, then remove the next line to test it\n",
        "  raise NotImplementedError(\"Implement the compute_accuracy function\")\n",
        "  #############################################################################\n",
        "\n",
        "  y_pred = model.predict(X)\n",
        "  accuracy = ...\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "# Uncomment and run to test your function:\n",
        "# train_accuracy = compute_accuracy(X, y, log_reg)\n",
        "# print(f\"Accuracy on the training data: {train_accuracy:.2%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyDFWqkctTyU"
      },
      "source": [
        "# to_remove solution\n",
        "def compute_accuracy(X, y, model):\n",
        "  \"\"\"Compute accuracy of classifier predictions.\n",
        "\n",
        "  Args:\n",
        "    X (2D array): Data matrix\n",
        "    y (1D array): Label vector\n",
        "    model (sklearn estimator): Classifier with trained weights.\n",
        "\n",
        "  Returns:\n",
        "    accuracy (float): Proportion of correct predictions.\n",
        "  \"\"\"\n",
        "  y_pred = model.predict(X)\n",
        "  accuracy = (y == y_pred).mean()\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "train_accuracy = compute_accuracy(X, y, log_reg)\n",
        "print(f\"Accuracy on the training data: {train_accuracy:.2%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxYTYyTYtTyU"
      },
      "source": [
        "## Section 2.5: Cross-validating the classifer\n",
        "\n",
        "Classification accuracy on the training data is 100%! That might sound impressive, but you should recall from yesterday the concept of *overfitting*: the classifier may have learned something idiosyncratic about the training data. If that's the case, it won't have really learned the underlying data->decision function, and thus won't generalize well to new data.\n",
        "\n",
        "To check this, we can evaluate the *cross-validated* accuracy.\n",
        "\n",
        "\n",
        "<img src='http://kordinglab.com/images/others/justCV-01.png' width= '700'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMN1ZrGItTyU"
      },
      "source": [
        "### Cross-validating using `scikit-learn` helper functions\n",
        "\n",
        "Yesterday, we asked you to write your own functions for implementing cross-validation. In practice, this won't be necessary, because `scikit-learn` offers a number of [helpful functions](https://scikit-learn.org/stable/model_selection.html) that will do this for you. For example, you can cross-validate a classifier using `cross_val_score`.\n",
        "\n",
        "`cross_val_score` takes a `sklearn` model like `LogisticRegression`, as well as your `X` and `y` data. It then retrains your model on test/train splits of `X` and `y`, and returns the test accuracy on each of the test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kCMRuYstTyU"
      },
      "source": [
        "accuracies = cross_val_score(LogisticRegression(penalty='none'), X, y, cv=8) # k=8 crossvalidation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "k8lLRPXQtTyW"
      },
      "source": [
        "#@title\n",
        "#@markdown Run to plot out these `k=8` accuracy scores.\n",
        "f, ax = plt.subplots(figsize=(8, 3))\n",
        "ax.boxplot(accuracies, vert=False, widths=.7)\n",
        "ax.scatter(accuracies, np.ones(8))\n",
        "ax.set(\n",
        "  xlabel=\"Accuracy\",\n",
        "  yticks=[],\n",
        "  title=f\"Average test accuracy: {accuracies.mean():.2%}\"\n",
        ")\n",
        "ax.spines[\"left\"].set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq42UZDQtTyW"
      },
      "source": [
        "The lower cross-validated accuracy compared to the training accuracy (100%) suggests that the model is being *overfit*. Is this surprising? Think about the shape of the $X$ matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP8FVeZRtTyW"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIxO45gFtTyW"
      },
      "source": [
        "The model has almost three times as many features as samples. This is a situation where overfitting is very likely (almost guaranteed).\n",
        "\n",
        "**Link to neuroscience**: Neuro data commonly has more features than samples. Having more neurons than independent trials is one example. In fMRI data, there are commonly more measured voxels than independent trials.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1IFbNWFtTyW"
      },
      "source": [
        "\n",
        "### Why more features than samples leads to overfitting\n",
        "\n",
        "In brief, the variance of model estimation increases when there are more features than samples. That is, you would get a very different model every time you get new data and run `.fit()`. This is very related to the *bias/variance tradeoff* you learned about on day 1. \n",
        "\n",
        "Why does this happen? Here's a tiny example to get your intuition going. Imagine trying to find a best-fit line in 2D when you only have 1 datapoint. There are simply a infinite number of lines that pass through that point. This is the situation we find ourselves in with more features than samples.\n",
        "\n",
        "### What we can do about it\n",
        "As you learned on day 1, you can decrease model variance if you don't mind increasing its bias. Here, we will increase bias by assuming that the correct parameters are all small. In our 2D example, this is like preferring the horizontal line to all others. This is one example of *regularization*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyeenxq-tTyW"
      },
      "source": [
        "-----\n",
        "\n",
        "#Section 3: Regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "wMb5KAf7tTyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "08e9f8aa-7da9-4089-9914-0acaf719890d"
      },
      "source": [
        "#@title Video 2: Regularization\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"b2IaUCZ91bo\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video available at https://youtube.com/watch?v=b2IaUCZ91bo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://www.youtube.com/embed/b2IaUCZ91bo?fs=1\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f4cdb6984a8>"
            ],
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAUDBAgICAoICAgICAgICAgICAgICAgICAgICAgICAgICAgIChALCggOCggIDRUNDhERExMTCAsWGBYSGBASExIBBQUFCAcIDwkIDRIODw8SEhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEv/AABEIAWgB4AMBIgACEQEDEQH/xAAdAAEAAgMBAQEBAAAAAAAAAAAABwgEBQYDAgkB/8QAXRAAAQMDAQMGCQISCAQEAwkAAQIDBAAFERIGEyEHFTFBU9EIFBYiMlFhkZNxgQkYIzQ2QlJVVnJ1lJWhsbTT1DNic3Sys8HwN4K14RckNZIlQ9JUY2R2g6KlwvH/xAAaAQEAAwEBAQAAAAAAAAAAAAAAAgMEAQUG/8QAKREBAAICAQMDAgcBAAAAAAAAAAECAxExBBIhIkFREzIjQmFxobHBgf/aAAwDAQACEQMRAD8AplSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UGLSsrm2R2D3wl91ObZHYPfCX3UEkUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSg0N/vi4zobShKgUBWVE54lQxw+Stf5Wu9i371d9eO3H1yn+xT/jXWhoOk8rXexb96u+nla72LfvV31zdKDpPK13sW/ervp5Wu9i371d9c3Sg6Tytd7Fv3q76eVrvYt+9XfXN0oOk8rXexb96u+nla72LfvV31zraCohIxkkAZISMk44qUQAPaeFS5ymeDrtHs9bV3W4Ih+KNLZQ4Y8neuIL6w2glOgDTrUkZz9sKDhfK13sW/ervp5Wu9i371d9c3Uys+DXtOuzC+paiGGbbzolAkkylRfF/GgAwG+Lxa6EZzkgUEfeVrvYt+9XfTytd7Fv3q765upc5M/B42j2htqbrb24niji3m2zIkhlaywooWpKSgjTrCk5J6Umg4fytd7Fv3q76eVrvYt+9XfXOKGCRw4HHAgj5iOBHyV/KDpPK13sW/ervp5Wu9i371d9bTY/kj2lu8fxu3WabJjE4S+lsIbcI6d0p0pDgGMZTkA8K4p9pTalIWlSFoUULQsFKkKSSFJUk8QoEEEH1UHQ+VrvYt+9XfTytd7Fv3q765uu65JOSe9bUuPotEdp0QwyZLj0hlhDXjG93OQ4rWvVuXfQSrGjjjIyGp8rXexb96u+nla72LfvV31NLXga7WkZLtnSfUqa/n/9sUj9dc1th4L+2VtQp3mxM5pCSpSrc+3JWAOpMbKZCz7ENmgjvytd7Fv3q76eVrvYt+9XfXPyWVtrU24hTbjalIWhaShaFoJSpC0qGUqBBBB4jFedB0nla72LfvV308rXexb96u+ubrKtFuflyGosZpb8iQ6hlhlsaluuuqCG20JHSoqIHz0G68rXexb96u+nla72LfvV31n7ccle0NkjplXW1SYUdboYS87uyguqStaW8trOFFLayM/cmuMoOk8rXexb96u+nla72LfvV31zdKDpPK13sW/ervp5Wu9i371d9c3Sg6Tytd7Fv3q76zrFflyHt2ptCRpUcgqzw+WuNrdbGfXQ/EX+wUHcUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSg4vbj65T/AGKf8a60Nb7bj65T/Yp/xrrQ0ClKUClKUClKUCv0ocX5XcmRVwffmbPkn1LudvRk/IfHofzYr816vz9Dq2l8a2fmWxagpdsnlaEfcxZ6N4gY68vtTD89BR/YewrulzhW1vIXPmxogUkaijxh5DRXj1JCio+oJNfro1FYS14oEo3SGEtbnhgMaS0lJT9wUpUn/lNUZ8GLk2MflLnR1NqSxs67c32wRlKkKWqJA1E54qalJeTxz9S9hFTvZ+Uje8qEyyBweLt2BqKlGeC7hHWLkpSOPSI8t9KuGcsD1HIfn3t1YlWu6TravUVQJ0qJqUMFQjvLaSvo+2CQrI4HUK/Qa/L8juTEtj6hJjWNuONHSi53MBDi0ZHEplzHHOI6EEkVB/LrybiVyrQomgKYvTtuuLqCnzCxHSpM9PRxKkW6Qo563K7D6JHtRu4Fss6FHVKkuz3wlWPqcRvcspWOtClyXFAdGY4PUKCj9TB4JszZhi9uO7UtxVQ2oLz0VyYl11hExpbZCVxkApfKmS/hC0r85CcAqIqH6UH6vci3KTA2ohSJtsaeahxJ7tubL6ENF7cMRnd620hR3bJEhISlWFYTxCegflztx/6pO/v8z94cq9P0OT7FZf5flf8AT7XVFtuP/VJ39/mfvDlBp6uT9DM9K/8A4tm/bdKptVyfoZnpX/8AFs37bpQc74R/L/tdadqblbrfdzHhxX2kMMiDbXdCVRmHFDePRVOK85aj5yj016ckvhj3ViQ0ztE0xOhKKUOzI7KY81nJALxbaww8kdJQlCD6jw0mK/C9+za8/wB5Z/c41RRQX78MrkpgX6xq2otYZM2JETPXJYCS3c7WGg6pS1J4LW2zh1DvElDakcQUlNBK/SzwRXVTdgLeiUd4kx7lEJXxzHbmzI6EH+qloJR8iK/NOgVdTwHOShq3RF7ZXgJZG4eXbd+nQIsNKF+M3JeriN4gLSg8PqetXEOJxB3gpckC9qruPGEKFogFD9xcBKQ7kkswUKHHeOlKskYKUJcOQdOZp8NDlhQJLGyFpWlDLD8UXdbICW/MU2pi2N6RgNoGhTgTwylCMjS4mg7v6Il9ibH5bh/uk+vz4r9B/oiX2JsfluH+6T6/PigUpSgUpSgVutjProfiL/YK0tbrYz66H4i/2Cg7ilKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUHF7cfXKf7FP+NdaGt9tx9cp/sU/411oaBSlKBSlKBSlKBVkfoeu03im07kBS8N3WA82lH3UmIRKaPzMolj/mqt1dVyQ7Scz3623PUUIhz4zrxH/2feJTJT/zMKdT/wA1B+m1h2Qj2u8Xy/qUEc6t29byieDaLbEW24r+qCMKPr0A1+eXJ5ygrG3cbaF0lHjN9U++Vqzuo1wfWy+nOehEeQtIHQAkDoq4nhNcs1iTspc2rZebXNmy43iLTESfHfeKJi0x5CwhpZVhLC3lZx9qOjNfnRQfrTeNjW5G0NvvagjVbrddIgyPPLsxyDuVJPUlLSJwP9uKoF4bO1Ium2M0IUlbVsQzamyk54xgpclJ/rJlPyU4/q1cvZLl62eVs/Gny7zbEzhampMqEZ0cS/G24oW/HDBXvC6XUrSE4ycjhxr8071cXZkl6W+rU/KfdkPK+6dfcU64r51KJoMSlKUH6A/Q5PsVl/l+V/0+11Rbbj/1Sd/f5n7w5VxPAL2+sdr2clRrld7dAkKvUh9LMyYxGcUyuFb0JcSl5QKkFTTgyOtJqm+1shDtwlutqC23ZklxtYzhSFvrUhQzxwQQfnoNXVyfoZnpX/8AFs37bpVNqtb9D22wtVqXehc7lBt3jKbVuDNlMxQ7ujcd7u1PKAOneN59Wseuginwvfs2vP8AeWf3ONUcbO2WVcZTMGCw5JlyXA0ww0NS3FnqHUEgAkqOAkJJJABNX9202K5LLxOfus+62d2TKWlb7qdpWmkLUlCWx5jcsJT5qEjAx0V4ReUnkw2LaXzQYbkhSCNNqQ5cZb6Qc7tVxdUpITnB0reA6wOFB1F/UzsHyeqYLrYfg2tcVlQzpfu00L4tp4KUgy33HCOkISonGCa/NGpW8InltuG18tJdT4pbYxUYVvQsrSlShhUiQvA3spQ4ZwAhPBIGVqXFNB+gPgw8pWxdm2XgRDdoEKUtov3Btxa231TnDpfW9qSFFXmJSk9GhDeOAFeXiHI649vS9aXZC3N4XF3C4uOuPKXqK1LW+VLcKjkk5JJ41QOsm1upQ+0tRwlDralHBOEpWCTgcegUH6p8t0fZp23Np2qMYW3xtot+NOvMt+OBp/dYUwpKte73/DOOn2V+aHLC3akX24JsZQbUmUsQi2p1Te6ATndqe89TevXgnORjBIxVtPDs5QbFc9mWI1uu9unyOd4ru5hy2ZDoaRFmhTikNKJSgFaRlWOKgOk1R6gUpSgUpSgVutjProfiL/YK0tbrYz66H4i/2Cg7ilKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUHF7cfXKf7FP+NdaGt9tx9cp/sU/411oaBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBW62M+uh+Iv9grS1utjProfiL/YKDuKUpQKUpQKUpQKUpQKV/UpJIABJJwAOJJ9QrobbYEJQHZSsAnCGUZLizjISdIJz7Bk+vFdiNjQMtKWcISpR9SQSfcK9XILyfSbWn8YY6fYa655RbRu2EBoHp0gFXyEjI1ZOPtj6q5+a+hKvOJJ6xner68kj1fLVsYvmUe6GtUwsDJQrHr0nHvrzraxpi85Qh0+3UM8fWOistUzOEqYQvJOUuNJBPyLGDnp66Ti+EtufpW6lWtsjUlRZPZLysfKF9IHyiv4zs865wbUgqPog5SFHONKSR6WcYzjpqE47fA01K9psVxhZbebW04ACUOJKVYIyCAelJHEEcDXjUApSlApSlApSlApSlBxe3H1yn+xT/jXVnvBp2LhXXYCdb5LMfx693S5R7S8tCN6JcS1xpkdCXSNYSHILyyEn0Ur9ZqsO3H1yn+xT/jXUv7K8rMG0bObNsxZC13K07Sv3WfFQ06k+KKL7Smw84gMr3sZ1SMJWSN4c4oJG8E/YeE1sxcHZ8dldw2hj3hEBt9tC3G4VnjOR33mw4nU2sTJKkK0+prj1VV3YGywZ8otXG6s2eKhlx5ct6O/KyUaQGWo8Ya3HlaiQMgYQrjnANnn+XfZ9e2zUhuUqPs1Dss63sOiLK0Kk3AmVKeTGS0XxreLbZykD/wAuD0HJiLwWNrLRaJ8565SE2+U9a5Ee0XdcNU9FrnuYCJPiyELJXjGF6eASpJIStVBp+WDkr5ji2+5xLi3dbVdkv+KzExX4LqXo69LzL8SQSts5PA546F8BgE7OxcjsRu0xLxtFtBG2fj3TWbYyqBLuUuU036UhUeKQppjikhfHIWno1JB6nwjuUC2XLZy0WyPf39oLlAnTHp02REmRlPCQFrStvxlAG5QVhpKc50tjzQOA87tfdmNqrFZI9yvitnrps/D5rdS9bplwjTIjYbS0+wYY81zSgEpVglSljGAlZB4FUVprb1DDLyJTLTV2aakpQpCJLaGXUNvpQvzkpWkBQSeICuNc3tXyNRmbHLvVp2hg3xFpkMRruzGjSY/iq33EsocjOvn/AM3HLqwA6lKUqAUpJOkgevgy7VWjZ3a8TZk481x0XFhud4rIy+hbbjUd3xVtK3W94NKtJB06sE8M1gcl21tvhbLbVW2S/u5t3asabezunl78w5kl2SN42gtt6UOIP1QpznhmgytgLdJXsNtHKbTa/F2JVoTIVIgl255dlstt+JTQ6EsIBX5wUheQpeCkqzWLyUckbV6tE69yr1FtEG1SGmpjkmO8/pbdSkhxtLKtTjpWpCEtAZUpQAOSAfbYXbG3RdiNorO/IKLjc5VochMbp5QeRFmMOvqLqUFpGlCFHC1AnHDNf3YvbK3R9hb9ZXpBRcrhcLY/Ej7p5QdajvxlvK3yUFpGlLa+ClAnHDNBqOWbkx8n02+VHuLF2td6jLk26eyy5GLgaLYeQ7GdJW0tO+a4E584ggEEDotlORCO7Gti7xtDEss3aEJXZoC4cia4+y6pLcZ6W8yoNxG3lqToKs5CgekLCddyrbX2+dsvsrbYr+8mWhi8ouDW6eRuFS5UZyOA44gIc1JbWfMKsY44qXLNyzR5ljs8eNtk/slLtVuYtk6G5an7jHlohtoZZmx3Y7K8OFCeKFEE5A4aNSwrLtps7KtFwk2yYlKZUJ9cd4JJUgqQcBbaiAVNqGFJJAyFDgKlDwKojT+2tuafabebU3cdTbqEuIVpt0pQyhYIOCAfmqNuUK7uzrpMlPTl3NbklwC4OM+LrmtNHdMSVR+lkraQ2d2eKc4PRXZ+CttZAse1UK5XN8xoTCJodeDTz2kvQZDLY3bCFLOVuJHAHGePCgjBfSflNTBslyLxnYNul3raCNYl35wps8VyFJmuyEa0tIfkqZUlMWOpxaAFrJGFhXAZxoduNk9mYkNb9s2tF2mBbYRB5huMDWlSsOL8ZkLLadKcnB6cYqadmuWhiVs/aYbG1z2yM+zxRb5bC7W/cY1wYYShEaWw5HaWUOBtOChQBKlKHQkKUFfb5sQ9bb6qxXSRHgOsTERZMtZcdisoWUlMsFtGtTBaWhwZSDhQyE8cdhtnyPxmLE5tDZr43e7fFlNxJpNul2x1hTxSlp1tuWSXmStaE6hjivrwoJ+tk9srenbpq736aq+29uarf3F2EUGW21FXGgzFwCNSQ2pMZZbwVAM8Ao9MocrXKnapOy99tq9q3doLjcp0KTBRzbOhxY8Vqew6IscOtBtCkNNqWr0QcpA1EEkIr5JOR5q92iZe5d7i2eBbJKGJjsmO6/obW2hSXGw2sFxxTjjbaWhxUVDBzgHX8kfJZ5S3ada4VyjtIhQ5sxmdIacRHktRX2WG1LTnWw24HkrKiFFAB4E1s9kdsrdH2DvdkdkFNyn3S3yIsfdPqDrLDkVTqy8lBaRgNr4KUCccAa+fBe2xt1luFyfuUgx2pWztygMKDLz2uVIXFUy1pYQop1BtfnEBIxxIoPnlA5II8OyeUFnvsa/W5qbzfOWzEfhORJJAKDupCiXGSVJGvzf6VsgKBJT7WW2yTydzpQTazFTtIyypTkFS7sl7xSKobi4b3S3F0qxu92T57vnALIr52Y2ytrOwN2sjkgpucy8w5cePuXiHI7Qi7xe+SgtJxul+apQPDgONfNn2xtzfJ9NsS5BF0f2jauDUbdPEKiJiRWlO74I3Q89pY0lQVw6KD72G5HokzZ9O0ly2hi2a3ePOQHN9Cky3g8lKVNhhmMrW+tWokpAGlKFqJwk1znLXycO7M3BuIqWzPjS4bFwgTo4KWpUOQVhtzSSdCstr4BSuGk5woVv7hthbl8nsaxJkE3RradVxcjbp4BMMwJLAd3xRuj9UcQNIVq49GK8+X/a633VjZxEB/fqtmytrtk0bp5rczYyFB5nLyEhzSSPPRqSeomg6W3eDwyl232657SwbXf7uy0/FtDkOU/oQ+Tum5E1tQaZkqCVANqHnLTpBOQTHUzYBTe0y9mzOitrbua7aZ8kmPFCm3S0XV5JKUkpOBk5JA66sXaLps1tbtbYL65OuEO96rWX9n02x95T0uGoPMyWZ4IYbtwSlLylEElpknCSrCYP5TWrfL27uaLhLVDtru0U9EuY00p9bLAmupccQ2gEqPmkAgK6c4VjBDh9tbEbZcJVvMiPLMOQ4wZMRe8jvbs41tL6x+wgjqqRPBX2MgXa7yH7sgu2uy2uXeZjIJAkJiaAhhRBB0ErKyOsNFP21R1tnEgsXCSzbJS5tvbfcTDluNKYW+wD9TWppYCkqxw4hOcZwnOB2fg58orOzd3VJmMKlW2dDkW25sIwXFw5OgrU0FKCS4lTaDgkZTrGRqyA7lPKZtjfI0pNo2bjLsbiJEFMK3bNty4UIKZGEpfbjk+NNtutL4kJyUnQAQK1/gYQmX7tdUvstPJTstdnEpdbQ4ErS5D0rSFggLGTxHHia7bkcvWx2y1xdnxdtZMu2rYlpatDlqurb29kNpQhTxSgRlvpShKS7pSFYHoio28FDa612e7TnbvM8RjS7FPt6JHi8iVpfkuxdGWoyFLI0tuHqHm4yMigh+rfWfYqHceSqNFEdkXnxK73+IsMoMl1q03daZAC0jeL1RpaEBOTxeRw4YqvfKDsxs9CjIdtG04vchT6W3IvMs627pktuKL++lKKF4WltOgcfqmeo1MWzXLRaba7sUGZKnI9pt86Bf2xHfAabuhYS+lQW2N+lCkB36lqzuBjOcEOn2K2JhQuTKe28wyu7XGzyNolLW22t6PDLrSIGhwp1pQtqOXBg9KnaqtsZ9dD8Rf7BVhLhyz2eVcdqwXyxbJmyzli2dR4vIIWIjKm4bISlsqZQ46484C7pCQ5hWMVXvYz66H4i/wBgoO4pSlApSlApSlAoKVjy5IQDx45wB1kn/f667EbGyhPpZVqUAVDoBOAn1lR6hW7t96Qv0j7MkdIzq4DPmpH3I+f2R69J1Hp81J4/1ldeB9yOge/rr1gyis9KggcPNzk9HAYPEn/fVi+sacmEhSXlO8GzhGcKWMHh5x05PX7R6+o4JwxCQkHQnOMnWfQGOBOonziOPHjjFYVvlrVpSlsqAwEMjIzx4ayM8PX/AK10lu2Jl3DCpJUEA6kt6cNp9WlvGCR90vJ9WM4rlssVdpimXKrlNqUEocSo/bBKgoJA9InTw6q+ERnnuKCpIJBCsDGAcnACeJ6PdUq2rkvaA4A/L0E/q9f7BXtcdhFxxlsHT68dHVx68dVcrmqsnDZH8kBCE5XrUkAkqKQejicD/fyVudk3kuIWhS29YwClfm+aegpwMnCurHDPGtNtFAdaVhYOPtVdHr4oUOkViWVSWXkOqUvSgnUEYC8FJGg5xwOR0EH2jpq/v3HhX2T7pdtSUTy1EkNNusJU+hzeIaDjx+qOMpQ8sZaKiW0JUFDBXmoo2h2NulvaD02GuOguFo5cZcLbg+1cS0tSkA8QFKACsHBNS7ZXIdwt8aZEQth4zlxHmnTq8XdSw64lbmlZCEqCRpUSf6VP2wr02/tsaPaJrMqezGmKZC24zzbwckKaebcS1HIRoWtZRjp83IJ4ZIyXtuV8447doApSlRUFKUoFKUoFKUoOL24+uU/2Kf8AGutDXYbSbPz5TocjQZklsNhBcYjPPICwpRKdbaCNQChw9orWeRt3+9Vy/MZX8Og0VK3vkbd/vVcvzGV/Dp5G3f71XL8xlfw6DRUre+Rt3+9Vy/MZX8Onkbd/vVcvzGV/DoNFSt75G3f71XL8xlfw6eRt3+9Vy/MZX8Og0VK3vkbd/vVcvzGV/Dp5G3f71XL8xlfw6DRUre+Rt3+9Vy/MZX8Onkbd/vVcvzGV/DoNFSt75G3f71XL8xlfw6eRt3+9Vy/MZX8Og0VK3vkbd/vVcvzGV/Dp5G3f71XL8xlfw6DRUre+Rt3+9Vy/MZX8Onkbd/vVcvzGV/DoNFSt75G3f71XL8xlfw6eRt3+9Vy/MZX8Og0VK3vkbd/vVcvzGV/Dp5G3f71XL8xlfw6DRUre+Rt3+9Vy/MZX8Onkbd/vVcvzGV/DoOvtvL1tdGhN2+PeXmYzEZENgNx4SX2YzaA2201LDHjCEpSlIBC8jA9VRq4sqJUokqJJJJySTxJJPSa3fkbd/vVcvzGV/Dp5G3f71XL8xlfw6DRUre+Rt3+9Vy/MZX8Onkbd/vVcvzGV/DoNFSt75G3f71XL8xlfw6eRt3+9Vy/MZX8Og0VK3vkbd/vVcvzGV/Dp5G3f71XL8xlfw6DRVutjProfiL/YK+/I27/eq5fmMr+HWx2e2duEZ7eyYE2O0EqSXHor7TYKsBIK1oCQSeFB0lKUoFKUoFKUoPOQ4EpJPVXPTZRJ6eOSOn/3H5gcVsb4/pwPVlXz44f6e+tAVZJOc8NIz71E/qq6keNj7zq80dA4E9ZPqHtNdPsfYnJboSkYQMBa/UDjzU+321obPEU84ltAOScfJnpJx11PGw1kDDSUpTjoz6z0ddQy5O3xC7FTc+XTbHbMxY6EjdgqwMk8T767VtttsZAAGPV0+ytHBQQAaz1rOMH1YrBa8+7bWkS3dtWnSOGDgH9VbJLCHEkEZBHRWliDNb23g/6VVe9l9KQ4ranZFDoUkJHncR7eH6ldHy8evjUJX6wLjvFCQcaiR68DpHy9xq2ZihY4j2e0eqoo5a9lilrx1sEaFDeaekdSVcOsGrOn6iYt2z7oZsMTG4QNcGNZKQFIGgYKTp3ihnIynBTwz19WOgmva/bRS5zcduW7vvEmiwy4tKd9u/MAQ48BrcA0DGonHH11mac+YcHVxbUDjJxnT8hAPzj2Vp7q1odP9bz/AJNWcj3g16Fp283JEsWlKVBUUpSgUpSgUpSgup4Ev2NOflWX/lRanKoM8CT7GnPyrL/yotTnQKUpQKVHPL5ysxdkILE6VFkS0yZYiJbjqbSpKiy69rUXCBjDRHD11C307tn+8ty+NF/+qgtfSqofTu2f7y3L40X/AOqpY8Hzlvh7ZeO+KQpMM27xTeeMKaWHBL8Z0aC2T0eLLzn7pNBK9KUoFKUoFKx7jOYjNqekPNMMoGVuvOIabSPWpayEgfKa8Nn71DuEdMqBKjzIyytKJEV5t9lZbWptYS60SlWFJUDg9VBn0pSgUpSgUpSgUpSgUqFLz4SVki7TjZhbE0vGWzAXNCGvFUTH9CUN6d5vC2FuJQpekYVngQNVTXQKUpQKUpQKVWLZ7wg7zI5QFbKrjW0W5NynQg6lqUJu7isSHG170yS1rKmU5+p4wSOHTVnaBSlKBUPeGN9icr+9W799ZqYah3wxvsTk/wB6t376zQUbpSlApSlApSv4aDnb27lZ9QOPd/3xWuc4YH+yenNZkz08no4n585H7BX3ZokV9eH5bjCtXAIimQDgZ88h1BSOrICvkq/irsRt1XJzCOoOaM/KcfJUjSL5LZGGm0EYPE8fm6RXMWqeiHvGg22G2VuNFZQla17pRSVlSwdOojOE9GcccZpP26LKUL8UStt0rCMeaTu9OrIwR9sOkDrrNPqlqjxy7ax7XuKIQ8gIPrGcH3110ebrGQc8QfdiomTeULSHC0WVEBSm1JSkp4lOejo1JVx9ldPsncS6SMOBKUpJVhJzqAUAElYOMHrxWW9WzHw7V+/IY4qUfkAJr7hbdu5ARHUQTjzlAHp6cCuSuVzZCMhOXAtSSlWCPNxjo6+v2AitHD5QCxIDDcQyHFEEYSEAhQJw2lKdSuA6SeNRrSZ9krT28rJ7N3F15IK2sZHUa2N3gtyY7jC06g4kpIPWMceHzVyuxdxjLdVGfiJYlM4DqBpWkKwFea4kYzgg8Dw6Dg10slhYmoaTrDD0V1eUKJUh1txOCnXlIGCB1dPXwrLaIm3wsiJiPlSm6zBGccZBVhh9aN4OhCkLx0DpGBnhXvtAj0F8OIIGOI0+asEHrHnK41vuVKNZ22jHgsTW52/dMt595C2VNBa9SAj0talYORpAAPT0VzK1BUZHE5Qlvp6fRAI/36q9rmsTDysldbhhUpSos5SlKBSlKBSlKC6fgSfY05+VZf8AlRanOoM8CT7GnPyrL/yotTnQKUpQa6/2KDcG0tT4cWa0hYcQ1LjsyW0uBKkhxKHkqAXpUoZHHCj66gXwytiLLD2MuMiHaLXEkIct4Q/GgRGHkBdxioVpdabCk5SpQODxBIqxdQn4cP2DXP8AtLb/ANTh0Ef+AVsfaJ+zDz06126a8LxLbDsuDGkOhtMWCUoDjzZVoBUo4zjzj66svs/s3brcFi3wIUEOlJdEOKxFDpRkILgYQnURqVjPRqPrqA/odv2Jv/luZ+6QKsjQRby78t9s2PVETcI06QbgJKmvEkR1hAjFgL3m/fbxnfpxjPQro4ZkHZi7tXCDFnshaWZ0WPMZS4AlwNSWUPNhxKSQFhKxkAnjniap99Ew/prD/Z3b/FbqtLyLfY1ZPyHaf3CPQcRtV4RFnt20ydlnolyXOXLt8PftNRjEDtyRGWwoqXIDmhIlN6jozwVgHAzMlfn7y1/8Ymvy9sp+72ev0CoKceHhyuW95iVskmPMFwiS7fIckKQx4mUqjIlYQsPF0q0SUDigcQrqwTp/Bq8JeybO2CHZZkO6OyGXpJW7GaiKYxJluvIwXZKFnCXBnzekHpqSfD82ct42bcuQgQhcVT4DSp4isCapvC07sytG9KNKUjTqxhIFengX7CWOZsjAmS7NapUwvziZci3Q35JLU98NkvutFzKQlIHHhpGOigslXMcpW31q2dhGfdpSYzGoNtjCnHn3TxDTDKAVuL6+AwACVEAEjp6oD4QS5G1/KS1YVPLRDjy49rZCFEbhhKEP3J9CVZQZJPjB1Y4hlhJ4JFBKb/ht2UO6UWa6KZz/AEi1xEO49e5Dik59mupv5H+Vqy7VR1PWqQouM6fGYchAZmRir0d61qIUg9AW2pSCQRqyCBsbZycWGNAFratFvEENhox1xWnEuJxgqdU4kqdcPSVrJUTxJzxqjb8BWwfKYzHgKcRBM+IhCFOKUHLXdQ0l1hfnZcDW9WlJXk6orazkgGg/Q+ol5W+Xu07NXeLZp0ec4/NYjyEPsJi+KtNyZT0VJecekIUnSphaleaQE4OTxAlqqDfRHkDylgq6zYmQfkTPuJH+I0E7N+FfYn79GskGNMmpl3CPbk3FBZbil2S+iOl1lKla3WAtwZUQnIBIChgmwdRHyL8hNgslvharbDlXNlMeU9cZLDb8nx5IQ4XY63QSwlDg8xKMadCTxVlRlygq5tFe9hP/ABDbjSLJPc2jE+G0JoKebjNWyy5GkrY8bAK0BTXnbr0kasEjVVo6oLth/wAZkfl21fukOr9UEf8ALRyu2fZNhp66KkFcreiLHjMKddkFjd73SpRSyjTvW/TWn0+GcGoUY8Nuyl3C7NdEs5/pELiLdx69yXEpz7NdTlyzI2YRDbmbUogKhQn98z4+jet+MFpxOhuNgmS4Wyv6iErzpzpOkEVs5afCD2Dulrl2hq0S5G8jOohSm7dCjtRpO7UI0hguPJfb0OaScITlORggkUFr9g9rrffIDVytkhMmI+DpWAUqQtJwtp1tXnNupPApI9R4ggne1Tj6Glc3i3e4ZWSw2u3Sm0dSHnky2nlj2qSwwD/ZCrj0FBNiv+Mrn5evH7rNq/dUE2K/4yufl68fus2r90ClKUCod8Mb7E5P96t376zUxVDvhjfYnJ/vVu/fWaCjdKUoFKUoFfLpwk/Ia+q8pR8w/JSBzExeVH5P28f9K9NjI5ek49eSfnrEkKyFkdZ/VW25M1DxzB608P8AtWi32pU5Tpadmkv6nRuypxSnClRSkhSzqUML4HziegnhXlc9mwoaHozLgScgqbHT0Z6MZrd7NuEYIrop6AtGeGcdOONeda+noUxo5d2cSoZU22jCN2CnAUG+ACEgn0RgcMdVddyf7PBJVgZ1YKjgA4SEpT7kpA+atXIdy5oRknPGpD5PJDLepLhGpSQAOGc5FR5jylETE+HNbU7FNrKykaQ5xI6EnUClwKI+2PmcT1JI6601p2QZbdQt5hta2sBtW9bykJOoBJCiRxqaNo4Y3OoDOBk/JXDxltrVwIOD11mpknjbTNPfTsdk47WkAMtIIyRpUFK44ySRxzUh2hjUAojGlBSPkJyf2Co92XbwRg1JC3dxFcdVw3bK3P8A2JKv9KqvMb8I33pQHlRlASJDmcl2Y/x1Ho1rPAHrxitPZHtSCjPUB0dQTgH31h8o8pRmFBSUBKnF4V0klfpHPWQOqsXZx76rpPFPAfNxIPvIr6HHT8OHm5Z9UxDdUr6d9I/Ka+azsxSlKBSlKBSlKC6fgSfY05+VZf8AlRanOoM8CT7GnPyrL/yotTnQKUpQKhPw4fsGuf8AaW3/AKnDqbK5Hlf2FY2ls8izyX3Y7Uox1KeYCC4kx5DUhOA4CkgloA+w0EOfQ7fsTf8Ay3M/dIFWRrguQvkwjbJ2xdsiyX5Tbkt2YpyQG0rC3W2WihIaSBoAYSeOTlR9gHe0FOvoltsdU1ZJiUkstuXKM4vqS68mG6yk+1SY75//AEzU1+Dzyh2iTslbXzcYbQt9riRJ+/kMsmK9CjIYe34cUN2klorBOAUqSRwNdtyk7E2/aG3O2u5tF2M/pVlCtDzLqDqafYcHoOpPQeIIKkqCkqUk1nR4D0PxrWraGUYWrO4FvZTK0Y9HxsvlvV/W3PzUEN7WbVxL3ypRrnBUVxH9pLA2w4QUh1ERy3w98kHjoWY5WM4OFJyB0V+kFV9T4KNhZulvuMGRLhC1LguIjthpwSXoUjxnfyHnQVqdcVgKIwAAAkAAAWCoIA8PtpStjXSASEXCApXsSVrRk+zUtI+evnwFb5DOxsSP4ywHo8uay80XUJcQ49LceaSUE5ypDzZHr1VM+3Oy8O9W+Ra7g1vokxvduozpUMKC23G1fauocShaVdSkJNVms/gWR4txamN7QvmPHktSG46rc1v/AKktLiUKlCToJ1JHEND5KC2dfn7y4Le2R5Tk3p1paojs2PdGykZL0SQgMz0t9A3qVGUkDPToJ4Kr9Aq4vlc5MbRtTDEO6sFe7KlRpLKg3LiOLAClx3SCBkBOUKCkK0Jyk6RgNvb9sLVIt4urVwhqtxa3xm+MNpjobAyouOLUA2U8cpVgpIIIBFUQuVwO3XKaw9b0rcgpnwyhwoUkC2WrdLkSVcMoS5unVJ14OZDSTgnFSY54DsYyNSdo3xF1ZDJtjapGjHomSJQQVZ+23XzVP/IzyQWXZRhbVsZWp94DxmdJUlyXI0nKUqWlKUoaB6EISlPWcnjQSDVCPoj/ANkkD8htfv8APq+9Qty9eDzb9rp7Fwlz5kRyPETDDcdLCkKbS88+FHeIJC8vqHTjATw6chMkT+jR+In/AAivWvlpGlIT9yAPcMV9UFBdsP8AjMj8u2r90h1fqoVung8W+RtYNrFT5iZKZkab4qEsbguRmmmko1FOvQd0CeviePXU1UFCPDuuC5W2UK3znlsW2PFhJSr7Vpqa+fHZaAQRrwgJJ/8AwqR1VYvbuy7G7KbMSn2YVqjtKtzzURxLcd2XPecjrRHQ1JWFPSHVqUk6tSsDKiQASNvy+8htq2vQ0uUt6JOipUiPOjhBXulEksPtrGHmNZKwMpUkk4UApQVFewngWWmJID11uki7NoVqTGajC3srwPRfKX3XVozxwhSOgccZBDlPoaH9Pff7G1f459XUqIfB/wCQiHsc9LeiT5cvx5phtxEhDKUo3CnFJUndpBKvqhHvqXqCgmxX/GVz8vXj91m1fuoVtHg72+NtWraxNwmqkqmSpviqksbgOSmnm1I1hGvQN8ojr4Dj11NVApSlAqHfDG+xOT/erd++s1MVQ74Y32Jyf71bv31mgo3SlKBSlKBWLc1YbUePAZ/WAP1kVlVrdoV4a9pOAPkBOT+qpV5HMlXmq9vfWfsM9omt+3UK1o9En5q/kCRuX23fuFgn5OhX6s1fbh2OVkLDNIwCe7qrq1TgW8Z6Rio92ekJcaQtJ4ED9YFbW+TXGY63EpU4UpBCUYK1cehIJHGvJvHq09XHPhnXFlSfqzI1LHpo1aNaT1pVg4Ir65PZMlEpbs4pQ0VZRu0KGkZ9BWVK1HH23D5BWj2f2rD6AUMOK6ApKxhSVFWkBQ6RxFddZX3HQCYoDZd3eohXp5IIGOkcDx6OFSy1jt0swz5d0xfZrjTza1svh4kNKSyWQy2rHD0jrIHRnFcncbc9EUFp1KRnz/X09IrvLRanE8PF8pSpKSR5uCpveDiT6Onr9fCuL2z21jruAtTDEkvNPJQ6/pbMRCgfObDqVkqXwUMY4aTWGI8+GuZ38JC2Dy6lKurgc9Xtrecte0qbRs7OnlAc3LLaEtlWgOKeebYSjVg4yXB1V4cn0UIYBAwOJHvI91RZ4cW0qWLPEtKVjfT5QkPI+2EaGNYVjPDL6menp0K9VQ6av1csV/Vm6me2N/Cou0t7duEtyU6lKS4vIbb9BtOAEoTniQMdJ6eJrJsbml0Z9Yz8h80/rIrToRxHtP7M1trYn6qkHoUdPvJA/aD81fV9uq6h4u5mdy6qWPPV8teVfTqiTk9OE5+XSM181hnlyeSlKVxwpSlApSlBdPwJPsac/Ksv/Ki1OdQZ4En2NOflWX/lRanOgUpSgUpSgUpSgV5yX0NIU44oIbbSpa1qOEpQgFSlE9QABPzV6VDPhmbVrtmycpljKpd4W3Z4raUqWtwzdQkpShHEkxUSEj+stHTkAhIewe3NpvrLj9onNTmWXNy6toLGhwoSsJUHEpPoqBzjHT6jXR1UzkAsa9iNtlbNOuZi36xwZLCzqKV3KFHV4zpUfNALjd0Vp6gtgerNsXVYSSOkAkfMKD6pVWtgeX3bLaSAuRYdl4T64a1iY+/LKIqlgBbcSG2t1C3JO7IUTqwNaQQMpKpg8HvlQa2stHOCY5iSGZDkObFKisMyWkoWdCylJU2pDrahkAglSTkpJISLSof5beV+VarjD2fsdtF32guLZfbjrd3MaNGG8w/IcyM53Lp06kAJbUoqHmhXEzuXXam13qz2K+7PQo0i7XCLGMyPKcdhuxpMmPGLkTClFL7RcXqQtRP9GcAKBUFjLxcmIcd2VKdQxGjtrefedUEttNNpKlrWo9CQAax9mb9DucRqdb5DUuJISVMyGVam3Alam14PUpK0LSQeIKVA4IrS8skxqPs9dpD0ZmY0xapzzkR/O5kJbjOLLLunjoVpwSOPHhWm8Gm4MS9lLZIiwY9tYdYdLcKKVlhjEp9KtCnCVqKlBSypRJKlqJJzQSLWgse2Vsmzpdtiy23p1uKRNjAOByOVEhOrWkAgkdKSer11v6rXKRzLyuNOAKSxtTZVNqVnDXjUZvJGM+ni2MdHHMv+saCcp+3FpYurNkenNN3WU3vo8I69663h5WoEJ0DhHe4Eg+Z7Rn02u2xtlo8X5xltxTNkJixQsLUX5CsaWkBtJOeI6eHEVSPlRu8le1k3bhDjniFh2stVlSEjUDHitPJnEYGd0fFwOHTzhU08qKOfeUvZ+1AJci2CE7fJJCs6XnFhTIKQMHDjFtOc9D5+cLI0qNvCQ5RX9lrEu7Ro7Mp1EmOwGn1LS2Q8pQKiW+ORivbls2/fsGzEi/Mx2n3mG4Kww6paWlGXKix1AqR52Eh8kfiigkOlaTYG8ruNpt9xcQlpyfboU1baCVIbXKjNPqQhSuJSkrIBPHArd0ClKUClKUClKUCod8Mb7E5P96t376zUxVDvhjfYnJ/vVu/fWaCjdKUoFKUoFc/tMs6gn2E+8DHCt86rCST0AZrkrk5rc+THDj04yfmyTVmPl1j6cD5f+9YcoY+etggZzWFNT0fJVzjsuTTabdkRXVYH/wApRPTx9A+31VLzElLiB11WNXA/J+0ddSZyfbUu6Ah47zB0hXXgdGr18OusefF+aGrDl/LLvX4Cd5qSnpIJCVFBJByCFJIwoHJz7a7OxPOhKEtvzG0pVr3ZSy6NYJOoLcQVHiesmtBb3mn0ggjPzfPXU2SOQU+eRWTJeYh6OCazzG3dWiFJnY3sqQQcFWXC0hWEbs6kNBKT5hxjor3nbLR0lIYbA3Z81QAypwgDWcdYArL2XiuKQNKie6vbbvbGBYIa5MolxTacoYb0l1xXQlIyQE5PWa8297WnUfw1zNYj9G4uV9hWS2KmTnUsR47eVqPpKP2rbaelbqjgBI4kkVRDlV25f2iuj1zfBQlWlmKwSD4vEbJ3TWQMFRK1rUfulq6sV88rXKZcdo5QclrDcZpRMaE0TuI+RgniAXHiOlxXHqGBwrlGs8Bx45PzD/v+yva6DpPo+q33T/Dxeq6j6k6jj+3qhPnj1JST8/HH+lZdsJKgf6//APX/APz31jOeYjJ9JfV6kjoP6ga2OzzOoDq8/OfZ116m/DLWNy6FSskn1mv5X06QVEjo1HHvr5rDLk8lKUrjhSlKBSlKC6fgSfY05+VZf+VFqc6gzwJPsac/Ksv/ACotTnQKUpQKUpQKUpQKq1y7W7yw29tuy6JMiPDskB+6XB+E6G5MeQ8ltTRbKkKSl5P/AMO0rIJSJayMddpaw2LXGbfXJRHYRJeAS7IQy2l91I0gBx0J1rA0J4En0R6qCoXhE8k7myTFv2rgXa+3Z+z3WGt1N3npkpbjKczhtaWUqQhbyWmlDiFB/iOFW7tVyZmRGpkdYcjyo7clhwcQtl9oOtrGOopUk/PXvcITMhtTMhpp9leNbTzaXW14IUNSFgpOFAHiOkCvqLHbabS00hDTTaQhtttIQ2hCRhKEISMJSAAABQVw+h0/YpJ/LsvP5lbun9Ve3gK/Wu0H/wCZ5n+W1Vg7XbI0RBaix2IzZUVluO02ygrIAKihsAaiEpGfYKW22RowUI0diOHFlxwMNNtBxw8C4sNgalnA848eFBWnlOvDey3KVGv91S4iz3W0c3Jn6FONRJKMakLCAVAjctk4HoySRnSrHK8u/KXab/tpsczaX/HGrfe42+ltoWIy3ZdwtZ3DLiwN4ttEdKlFOUjfoGSdQFwLvbI0xlUeXHYlML9NiS02+yvHRqbdBSfnFQZy58l0yVe9j3rHbGEW6yXdcqemMYUNmIyqZaHd4lgrQV5RFeOGkqP1Po4jISL4QX2J338h3T9zerQeCB9hNm/uz/77JqVJTDbqFNOoQ424kocbcSFoWhQwpC0KGFJIJBB9dfECG1HbSyw02y0gYQ00hLbaASSQlCAEpGSTwHWaD3qt3hztPQI9k2niI1SbBeWyeJCSxJCXFB3HS2p2Iy2f7c+s1ZGsa5QGJLZZkstSGlEFTT7aHW1FJCkkocBSSCARw6RQVb2b5OlOckUplxJXMuEORtG4oAqdefS6mfHVnGVOLjRY6D1nURXr4CDb91du+1M0JVJkJtlmbWBxItsCMiQrJ7QJgqIHW2enqtG3GbS2GUtoS0lAbS0EpDYbCdIbCANIQE8NPRjhXla7bHit7qKwzGayVbthpDLeo9KtDYAycDj7KCF/DntT8rYyYWG1OGLIhy3UoSVKDDbwS65pSM6UBzWo9AShROACai/whuXCwXnYU263yHJNwnR7cXIjcd7eQRDkRZEpcxRRoQhBYLeQo6itJTqTlQuCpIIwRkHgQegj1H2VpIOx1oYS6li1W5lMn65S1Bitpkedq+rhDYDnnAHzs8RQavkRUDsxYyOINhtB/wD4+PXYV5xmENIS22hLbbaUoQ2hIShCEgJShCU8EpAAAA6MV6UClKUClKUClKUCod8Mb7E5P96t376zUxVDvhjfYnJ/vVu/fWaCjdKUoFKV/FKABJ6AMn5qDDu7oDZGccMn5OgfrxXJa9S/ZxUfX1msq8zVOLIGf6qejBPRkfdcT8gx7axWPuenj5xHR0HAHyY/VV9I1AyGuOo+rH+tYcv0h6gkH9dZzQ4K/wB9fdmtfcFYIHrbTn9YqYxVjvrf7GOecoeog1pCK22yXB4j2e/BqvJ9qVOUp2V9beFJPDrB6DUkbK3DWBqTx+XvqNtnvO4H567mwDd15Gbh6+CUpRb4401hBCOHSOn31XLwir+p1aWdWcq1HPHJA6T76liXcCGz1cKrfypSi/N6eHH3DTUOhxbybl3rMmqahzERrPE1mLIQCT6RwAPUB7PmPv8AZX8jAAZ4AJxx9vWT8g/bWK4rWSo5wOAGc8O+veq8b2fTiytQ9pAAHUOAA99dPs+OHDqGP/bqJPvz+quZYHXjzlcE+v5a6S0q06U8Bnq68JICj8hJA+Y1PJwnjbVP+/ea+q2tpsT8tSRHCV6xkcfR4ZwrAOOv3Gva77JXGKkuOxXC0nOXmhvWgBnipTedA4HirFZJpMeyEtJSv4DX9qLhSlKBSlKCY+Rnl4e2atyrc3am5oVKdk75c5UcgupaTo3YjOcBu851fbdHCu1+m5k/g+x+lXP5GqzKOAT04GcDp+auz5TtgXLF4iVzYs1Nxh+NoVF1aWxlIKcknW2dY0uDGrSvgMcQmb6bmT+D7H6Vc/kafTcyfwfY/Srn8jVZFOpHAqSPlIFfQOeigsz9NzJ/B9j9KufyNPpuZP4PsfpVz+Rqs9KCzH03Mn8H2P0q5/I0+m5k/g+x+lXP5Gqz0oLMfTcyfwfY/Srn8jT6bmT+D7H6Vc/karPSgsx9NzJ/B9j9KufyNPpuZP4PsfpVz+Rqs9KCzH03Mn8H2P0q5/I0+m5k/g+x+lXP5Gqz0oLMfTcyfwfY/Srn8jT6bmT+D7H6Vc/karPSgsx9NzJ/B9j9KufyNPpuZP4PsfpVz+Rqs9KCzH03Mn8H2P0q5/I0+m5k/g+x+lXP5Gqz0oLMfTcyfwfY/Srn8jT6bmT+D7H6Vc/karPSgsx9NzJ/B9j9KufyNPpuZP4PsfpVz+Rqs9KCzH03Mn8H2P0q5/I0+m5k/g+x+lXP5GqzKUB0kD5eFf2gsx9NzJ/B9j9KufyNPpuZP4PsfpVz+Rqs9KCzH03Mn8H2P0q5/I0+m5k/g+x+lXP5Gqz0oLMfTcyfwfY/Srn8jT6bmT+D7H6Vc/karPSgsx9NzJ/B9j9KufyNclyueEC9tFanbWu0NQ0uux3d+ieuQU+LvIeA3RioBzoxnVwz11ClKBSlfwig/ta+7vK06EDJPST6KfUSTwPHHCto5DWGQ9vkBSlLShrCFOHSgL1aNWvByMK06enjXltpYVRJTkeQ8XnWUs7w5AQFuR2nloA/qlwpz/V9tX0wzPlzuiHFohuKDimxrLSC46vPAJ84kg9Zwk+6vZcdxtI3iUoyMhKUlPRp6lcT8vR7TW/tDqERJ54J1NMtajp80P8AjLRzwz06Tw+5NaGfIDy1ugEJJwjJyooTkDJ9Q7hVkxoidvFC8Z68Y/WsYrDuZ89PsQke4f8AesyOrzT0ZWR6uAHR+z9dY1xT5/y95/VUZl1jM+utpsqvEtA6NWoe/q/36q16QAM+qv4FlDiVJ4KSUqB9qSDXLRuCs+UxW4FpwHqOPfXfQ86Qr1gVyOziEymW3E485IPD1jGfdXd2+L9TAPUK8nNXy9TFdq7w+rdq+Q/sqv8AtSomSpR4E/q6v9KsbOgahjHA1B3KnbdxJTjoJPV19OP2frq3pY1OlfVTurk1ZV5ozgcOHWSf+5ohGej0U9JHDUR6vZXohOBpHSek+pPXj2kmvZKMDT0YHVxxXrVh55DYKl8eA/Yker2Vl29et/OMJwUJHsQTx+XA/VX1b08TngOjH+mejHRx+WvaG2N4FZwAoj5dQA7/APZqyId3p1ezl/lW5RfjEYSEpWlQ1J0qyArRnziNfDpwVcQRkGUtnuWB5tRU/Hbf3ikuNOsAx3NI/pBxUtJfCkoPH0SMDKFVDsJhK3N2s4TrcySlS8p0rIQlKQSXCoBKcda01sbBCc1qty1tqe0JeZcUSjQ+lJ8xW8KdOoZSsKH3Kh6IBtxUrM+qELzPslTnHZ+/LkyJUHxR5IWplmOE25a0JBU87IkhpaH5IQnWkFCQSCMccDiNqNgp8RS1MsPy4yFLG/ZZccCN2cLDu7SQCnoK05T7RxA8rQ+qK+h0Nj+lUh9CmtemQ0rCg6SoZSfPGMHOT68VNlhuy2JiF2hSy6/4stqKpSlMulxsvSkLCjpCWkFSg5gKTrKfPAITZ1nSUrXdY/6qxXmZ8q1g56K/tTv4QuycB5l2+Qx4rIQ4G7hESkblx0vpY3qCAND+VoUrhhQVnpyVQRXjTExyvKUpXB3GxF42YZtkqNe7dcXpj0hK2Lhb1xw7FjJbb81sSnkthYcS6SFIUFh0AkaRizQ5Ktn+YreqWhc1q1RHpMF26TF25KkTVCYGJy2dLbccuqaThSVbsZHHKgqsfIddHIl7YWzaWr3IdQ8xHgOLbby6tO8DzbjqFIQ4hDTnnKGAlTnEdI7Kx7QtvO7S2/bGbMhqnIQ4Iy99J3E+LJVKZRFSNbaFN4jpSAAlxAT52Eg0G8222o2ssEVqSLVs7a7Y8+Y8du3xYclknQtxsLWhxWtK0NuELATnQchJIB5WHtlYr+oRtobbDtMp4hLW0FoZ8VSy6ThCrlEKil1j0Qpwk6Qc4bGVpi5dykrjtRXJD6ozBUtmKp51UZha8lxTLClaEKJUrJSATqPrNYilAYBIGeAyRxPqFBv9vdlZdlnu26YE71nSpDiMlqQwvJZkMk9LSwD8hSpJ4pNaNtBUQlIKlKISlKQSpSicBKQOJJJAwPXUvbcwJFw2Jsl5dTqdt78u0reKk6nIAkOtRCoE6lbtyOGgOnzlK6Dmo/5NP/XbR+W7R/1GNQYLFguC31xW4E9yU0AXYqIUlcpoKAKS5HS2XEAgg8UjpFYtwhPxnCzJYejPJAKmZDLjDqQrOCpp1IUAcHpHUasb4SvKhdLVeVwLQ6i35ZjSZkltiO5Ilvrb0NhxchtYDTbKGkgAA51ZJGBWBy4T13rYez32Shs3IS1R1uoQlBcSTPjvJGMBKXHYbDukcAQcAZoIGtNqly1FEOJKmLSAVIiRn5K0g5wVIYQpQBwekdVeVwhPxnCzJYejPJAKmZDLjDqQc4KmnUhQBwekdVW1262X2jtFvgWfZBhLTLbRcuU5D1vZkyZXmp4mWsHKiHFqUlPQWkpKQkpPM8o1ku8zYyS9tQ00i8WiU25AmF2Gp5+I65HbcbcVDWUEkOvJ08NRaYUQVDUQrjKgPtIbcdYfabkJK47jrLjbchAxlbC1pCXUDUnzkEjiKRoL7rbjrTD7rUcJVIdbZccaYSokJU+4hJS0kkEAqIzg1OnhF/Ytsl+Tmv8AptvpyEfYXtZ/dJX/AEt2ggrxJ/cGTuHvFkubpUndOeLpdICg0p/Tuw7gg6c5weivW5WqXFShcqJKiodBLS5MZ6Oh0JwVFpbyAFgBSclOcah66sfyY7QptPJ27cTHakuRbg6uM0+nWyJa5zDMV5xAI1Bp1xDuMg/Uhgg4Iw+Qe9zdq7s5N2gkCdHsMczIsUx47bDcqSopQ9u2kJ3hQ3HdKd5qwrQoEEcQgYbMXTdb/mu5+L6dfjHN8zxfRjOrf7rd6ccc5xWrjNqdUlDSVOrcUlLaG0lxbilEBKW0IBKlEkAAZJyKlVXhFbSmd4+JKPFt5vBbNxH8X8XzkRy7u9/r08N7rzq49Hm1JW2+zUSHt3s/PhtpZbvC1SXGkpCU+MMoO8eCRwSXESGSQAPOStXSo0FcYez1xeccZZt1weeYOl9lmDKdeYV9y+022Vtn2KArGZtslb/iqI0lcoEpMVEd5ckKSMqSY6U7zUB0jGRU8cv3K9ebZf5UG0vtwGIa2FvBEaM4Z0p2LHkLelKebUpSdC22glJT5rXT0aeq8I7buRaGbfMtTbMO532IFS7ilhpyQIsJDDjcZBeSpOCuerziCQGwPUUhV662uVEWG5cWVEcUNQblx3ozhTnGoNvoSopz14parZKlrLcSLJlugai1FjvSXAnONRbYSpQTnrxVgNsr09feTg3O5lD8+BcG0Nyd2htasz2YhUUtgJSpTEnSoJABKEnGcVkba317YvZizwbRu49wu7Spk2aGm3XCtDEdyQU71JSV65bTaCsKCW2SAAcEBXzmOdvlRvEZvjLbZdcjeKSPGG2h0uuMbveIaHWogAeupH8HXk0Yv8qQm4ImtxEQlOx3mQWkOPl5DQKXltqQ5pBWdI6xx4Agy14KfKJNvUqSxdVIlTIkULiziy01I8VefbEiK4WUJSpveIjLHDPBWc8K0ngY7YXKU45a5EouwLfa2zDjlphIYw+22kBxDYcUAlRGFKP6hQVym26THCfGY0iPrzp37DrGspxq0b1IzjI6M4yKyrfs5cpLW/jW24yWOP1ePAlvs8OB+rNNFHDHrqVuS683LbS9wYF/mGfBib+4LjLYisocLLYSEK8WaRqSpa2kqCsgoKx9tXrypcuV9bvMqPbJYgQbdLehR4zcaKtK0wnFR1rdLzSiQtTayEp0hKCgAAgkh5+BvCad2ifQ+y27u7VK8x5tK9DgmQWl+aseasJW4g9eFKHWajBezk6Q7IVCt06Sw3JkN64kGTIZbDbq06CthtSU6QAMZ4YqefBz2xfv22D9wksRmJB2eWw74o2ptDy2psH/AMwsLWol5WvGc+i22Pta4248ut8YuuIbzUW2RZZZYtbUaN4uYjT5QG3FqbLu8WgZUtKxhSiRjooIeUCCQQQUkpUCMEKSSFJIPEEEEY9lfypr8Mq0sx9oW3mkJQqbb2X39IA1vofkMF1WOlam22gT/wDd1ClApSlApSlApSlArNscVD0hpt1WhpS07xQ6Q2DlWkEjjjNYVfIbXr15IaZZfed0uFpZSlGgBCxxCiVYGM9OcEAirMVe62pRtOodNeloaS82EuKfS8slLcV5TDbYRvY2t8JDSGdHSAVqCk8AONcZtnc3JMlEtXHfx2kO4xgSIqBHcHm8CVJbaX/z/LXYSprZiIYbW5LdkNtILjLrYbU4ypttxpxa0lwqO5jOZIATvDnpqPdoFBvUwUkHUlSskndujPFPAZBbVjiE+kMjKQa32mZqpryxUuKWwrBOlchKSlI81ZZbJBKusgvA+zp9VeUhgjOM4SAM/i+ccezORj2VkRkpbjsk8Na5DqCftQVJYUsDo/8AkKH/AC+2vWa83uRjIUv0UniUtjiNR6CpRBJ91ZpXQ1sADXg8es+rAyf9K+bgnJB9n6zWS0xoQVZGtWkJHq6yfd/pXk9xCcdWAfnxnHzD9dcSYobyQn147/2V5OHKiR1H3nr/AF5rJ14BV19Xz8P2GvBCev5q64l3kWUVN7s5weKePokez2j/AA+2pngQjjHH/Wq+ci1yDcxLK1FKVE4x6lEDgD0kKCVfOatLBjq3YOB0A/L8mOBFYM1PU9CPFYtHv/bSyoyUp4/IM44nFQVy3FoOoSOKi4pYUR5wQlOhIIHAHifnzVgL+SlKlFJOhOcAdKiOAA9dVS5Rpzj85aRlaycIQnKlYySAlI4/NU+nxancqc19w0KHwD7f98f9+2vuTJSlIA6Tx+TpIzj31/Iuz1wdISiFKJIyMsrQCCcBWVgDTnhnorvbByXOBnxqe9uVgEiM2ElaU6eG8WrICjxGAOGOn1ej3QyuTYVg6lejhOD6zx6PWrjXs4klaSfNRwcwOHoHWc+0jNYTcgFRSoDLRwCSSOkjiE+3hn2V9TZxUnQMDJ6fVg5wc9WQKvqN7Emagl7AJzlQI83UOBCgT6J9XtruGIolstux1qRJaIU24XihkOEoIbQw5PWlvzi0NQbSMAE46KidiToTo6lnUR6gej9ldxsZPbOhpel5KlcWypjWOOSlKJY3LiVqS2SlRH9GgBQNLxrzBp1m18UOMNTEJSgTY+9W2GzlqbBWluSkt59LOgdAyUk9Oa6rYO+J8TYRlzxhp5zdPAHDLQCH3FEhJJXhbgDfFSlEY9FRrB24hqEBDu7cZCnVOBLiCxhyVFPjOnKlENlyGHRhSh/5ngTgVz/JxfxHaUkoS4XSy0jUV7tOWn1FxeBqyAjUCPOJQAME5Gnf1MH7KeLJV5ZVA2Bx1TSUSJLMR2QdZ84LmRi27pA06vqaUkA4TvD6WokVzqwvKHFHki4+8pTjhWw1GKlechpUuOrW4hKsAq3LpCOIQHAOJxpr1XjZ9bjXwuKUpVLrabI3ty23CLcGisLhymZGEHSpaG1gus59TjW8bI6w4R112fhE2cs3py4NLL9vviU3S3StRWh5p9CFOthZ+2bWrGj7VC2ejOKjiu/2E5QWo8M2a8wudrItwuoYC93Mt7ytRMi3P5GhRKlEtkpBK1ecnUsLDjtnrS/PlsQoqAuRKeQwygqSgFazgalKOEpHEk+oGpz5Hdi71bZt4sMu0g86WiS23cHYy34KHmmHfFiiWUhpcdxckBSMhWpDWQkpNcgNmNkHVpfhbXy7cEKS4lqdZpb0tlSSFJ0SIam0FxJAwpGcEDjXZ7L8r9l2a1iLN2g2lVIUlUuRPkOR4rKEaytcKLK1Ob8lWTqA1DGV8AKDkdotkIVksTsO/SZTe0Lzhl221Rpa5EaMyFojiRLaa1RELd0yTrKtZQlIT5yViuD5P5DbN4tjzq0ttM3e1vOuLUEobaanR1uOLUeCUJQlSiT0AGp75YNuYEfaR1naPZqPOhssti3y20OCa9FW1vEKy86hl+PvnZA0nTu1BeNSk8a3TVtqdcU02WmlOOKaaKy4WmlLUW2y4rispSUp1HicZoJM8Ka4x5W00hyM+zIbTHhtlxhxDretDI1pDiCUkjIBweByOkGt1tXeIbnJva4KZTCpabk8HIqXkGS2BIuq1KWyDrQkIeaVqIA+qt8fOGYUpQWH2r5o2+hwJCrrAtV+gsqjSY1yKG25IOlSyytRBUjeBTiVI14Dq0rSDgjgNtuTex2a3urcv8OfetbSY0G1oadZQC4jfGW8CpSRui4oE7riEjC84qNiKAUFjyxbdsNmLRCReINtudkabYdYnrS3vENR0RVqCStKi2sNMOBxAWB5ySAc6crZ0WGzbK7Q2pi+Q7hOXBlLkvNuNtsPSJUR2NGiQAVkyAjdpBUgq89/qzpTWYimKCbod6h/+GkiF41HEw3RvEUvNiSf/iUWRkMatZTukLXnGMIV6q5/wctvmLDdVqm55vnseKylJQpZZIWFsvlCPOU2klxKkpBOHiRkpwYypQTgrkSs2+8ZG1tmFj3mrV4yz42I2r621b7d77T9T3mc546M+bWw2g5S4N122s7zDiGbRa3UxmJD31FCi4Fh2QS7gtsE7hCdeDhrUcasCv2B0441/aDufCImsydprq9GdbfZW8wlDrK0uNrLcCI04ErQSlWlxC0nB6Umu18KO9Q5kXZwRJUeSWbW/vgw826Wd43bUoDoQSUKJZdGFYOW1eqoRr+UE2wLzD/8NJcIyo4mKujWIhebEhQ5xhSMpZJ1lO6bcXkDGEK9RrdsybVtpYLdAkXSLar9ZkBhszlIQ3KaDbbK1IKlJ1h1DDC1aMqQtpWUlJBNeK/hGaC1Xg/wbDszNlMSNoLbLuMiNvHXGXm0QIcaK4kqj+MuLw5LWpxThRwIRH9EYyqKvBU2zh2W7lVwcSxGmQjFU+vIQw8HWXWi6R6DR0LSVfalSScDJEVVs9mLJIuUtqDFCFSH97uwtYQk7lh2Q5lZ4D6mys/KAOugle3W5nYm7wrwxd7beLe8+/GW1AkIcm+IvNqy6plBUg6PqatQXgrQhPAL4bfbPkus15mv3i17U2aPBmurlyG5TqEuRHnyXZBKFOoUAVqWvduhsp146MGq+oIIyOsA+/jX9KR6hQWK5ClbP2ba55uFeUSYIsbja58xbMZlyd43FdfajuHShTIaaCwcq6HPOUE5qAbi8lUp1wHKFSXXAoZ4oLylBQ6+jjWHX9oJr8MO8w5t5iLhyo8tCLW2FLjPNvoSpcmS4lJW2SkKKFJVjOcKSesVClKUClKUClKUClKUH02nUQBkkkAADJOTjAHWfZXW2AQXpL7MNcqKhTDbZLiUb955o6m8tr3qEE5cICU/cniojPIV/YpLRKkEhRx52TqTpOpJSeohXHPTmtHT3pXfcheszw2my7+uO80hJckMFUqM6tolJZ3YZcADSUIcWuOpKtHHOpOdXXyO1KHX2zMWI6Ul1RWtpkNrcW5hSydKiCehWCAOLmOgiuohXRTDxfYZjMuEKCt0zoCtZQpSiAeK8oSc9I6sVr7kkSAEOBO7SQUtJQhKE4U4rgdOvpec+2+29gqyc9dIxSdue2ptzsYttqwdEdrr9HUtwKSr7kh5Lwx6z7a5x51R4k5A4dPDPXipInuqfDgcOd8ptSjjBBaQUAI+5SQpzI6y4r11pDs5G9Tnyazj9lVfUhZpzKnlltIz0Ek/OSO4VnRcLSvhndpUTnPQohI0jHEgkVvRY2AMYXj8b/tX3Hs7COhJJ1IUFEnUkoVq4EdR6D7K53waYthtCnnEKU2d2lLiXspIThIQFaVH7dIWCR1FNZeymw78+7t2lDiGVrcXqkO5LbcdtBeW+QCNQ3SSQARkkDI4kdDGvbzbhcw0rOrCFoy2kqxrKQCDk4Gck9ArybubqZSJidAeQyuOcAhDjDjTjDjbic5IU24tJIIPEcQQDXIvqdrd1nH2zzE+P9f3azY2NaS3crVeYl8hMPtsy1xklp+I49qCA81rWFMuhDiUupVp1ADrBM7bHXdyRA3jbiFrZQlRQtwBS0BTafqac5Ur6qg49SunFV/ZcCYLkANMFp5bSlvFlHjellYcS0JIAUWdYSrSrVxSMEcQd7shthKtbK2I7cVxLjYaKpLKnloQDqAbUHEhKs6TqwT5ierIPJtG9u1v+FNJ+dx/qb7g+pefO6STjhjJJ9QHD5uqsePbicdHHhkDA46h+3HuqJHeUGerGUxeHRhlf8WshHKfcxjzYZwcjLCz156nf95NS74UREpjTamzpWQnUOHDJP2i8gDq9L3mtbtdZllpSUpAyNIOcEkDHo9XFJ4nHRUdM8r94SAkCFgeuO5k9HT9Wx1ftrHm8ql1eGFiH0YylhYPo6O19RNQi2pSQ7tVbFxZCkn7YqI45ynURkmsYR1oQHFJUUFWArBwTjIGf9PlruNoJHjzyX30N6kN7oJQlSUadS15IKidWXDxz1D1V8tOhMcxi22tpXHz0kqHpdBzgemrq661R1MQOdttjcf0FK0JS+5u0uOhaWkuK4oBcSCOJOk8OBx66kW3bDKgutuSU7pKW1eMur3a2GpLSlKLeH0bpzKBjQogHSrCujPPW2QWGkspShbSVuuBLqdfF5AQtOrgoJ80KABGFcRW7f2ynORm4ji0OMMSG5KA4lS1bxpvdoSpSlkqaxx0nrPzVG3UbS8O92sUhFlShCN2ETAkoW+6VNr3DqXUJjuOussICsYDLq09BKUZwY82NmhtlzUje71cVpKNQGtf/mXEnej0QNBVqH3HCvBV9fMdUY6FIWsuLUUkurdUp1bjqlFWFOLLvnEjiG2xwwc4MGSplC20hJS5o1agcgtFSm1IKSNKklRORWnF1eOuOazvf7KrV3O0zbRKdVslJW5xYXIheLKGpIW6ZJLzqQvzlMYykKOkrUFLIGeMJ10k3bae9Cdt7haVHkLZdcy2reB5ohReQrXhK3FZUvAwpS1nAKia5uvPyX7p2mUpSqwpSlAr+EZ/3j9Yr+0oN7tpthcry62/c5SpTrLIYaUpDTelsEqI0soSkqKiSVEZJPE8BjRUpQKUpQKUpQKUpQKUpQKUpQKkzZJtUSzsylNbNQESX5ixcb82bnJuDMctsrag21uE+41FZWFJWpI1OLWOKMDVGddXa9uXmYTEF2Bap7cJb64Lk+K4+7D8Zc3z6G9DyGnGlO5XoeQ4nUTwIwAEg7V2G32ydtLcGIMR1Nq5ibt0N5reQWXr00wp6SqK5lKkNkuFtteUguAY81ONBs683dplveFggrkMMXN24693abFLajAKZnSA22WkIjB0F5KEgOHdJ4asVqpfKfPemvzXo1udVPiMQ7nGcjuqiXNMYJDT8prf6kyk6G8LZU3p3Y0gZVnya5SJyJDDrMa3MxosSXBbtbcVXNiolwVrnMvMrdU65v1hClrU5qUptBzwxQdrdbJGuVobU49YnZvlFabb45YYCoTbEe4BxtbTyjEYakYOFpISrTo4qOSK2mxV+jt7YKtDFotrEOHIvEGEtuG2m4R1QYc9ozHJ4G/eceSw4FhxRSRI6MpBMZzeUF9cF+2twLXEhPusyENQ48hlcaWwVaZjMgyS8uSUEIKnluAJbRpCccdlG5Xbg3J8eTCs/OTjZak3HxJ3xuWhTYaUX9MgNJcUAkqW0htSigZOMpIb6z2Vq32O0PR3NlG5NyhuT5jm0iN846lTpbYixkLjupaiIQghakFK1LVnIxWRPhWeCdp5cGHbrgxEb2eetqX2/G48N24vlElLReAUtpDi14SrgpLbQUFDIMfWXbRxiGzAkQLXdI0NTqoSbpGdfVE36gt5tpbD7RVHWtIUppzWgnq6q87jtrPkpuYkLbeVfFwlznVt4cHiD2+jJj6FBDaE4SjTpI0ISBjGaCSJ15YbTs4+mz2LfXtIF0Uq1RVofQi5+IBLLBTuoxU3rUpTKUqUoo4gJArVbRbMRnot9t8CI349Yto1qilttPjMi1S5bttRDU76biWH9wrKicBz2muGf2qlLTbUlLGLLkQ8IWCrMszf/MfVPP8AqpPo6PN4dPGu05Mtr1RblcNp5UqAh5xFxKrcC54xOmzCiQw2xGKVaYQlFtZdUs6PFiOPTQc/yxR4ka6Kt8JtlDVrjxra46yhCTLlxWwJsp9SANb6pCnUFRycMprjq+33luLU44ouOOLU44tXpLcWoqWtX9YqJPz18UClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gkilRvzlI7d74q++nOUjt3vir76CSKVG/OUjt3vir76c5SO3e+KvvoJIpUb85SO3e+KvvpzlI7d74q++gxaUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQf/2Q==\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1WFW7hFwjoc"
      },
      "source": [
        "# Summary of Video 2:\n",
        "\n",
        "Regularization with linear regression and logistic regression. \n",
        "\n",
        "in linear regression model, when data sample is small and the distribution of sample data is far from the true data distribution, the linear model could overfit to the data resulting in a bad estimate. Thus the model fit is quite different from the true model. And we say overfitting happens when we have less data. Moreover, we also show that in polynomial regression, when the polynomial order is high, which means high model complexity, the model could also overfit to the data resulting in a bad estimate. We can summarize this situation as more features. In general, overfitting happens when we have less data and more features. To overcome overfitting issue, people use regularization. It shrinks the parameter theta in GLMs towards zero. Thus, it can reduce overfitting. \n",
        "\n",
        "Here is some intuition with an example using linear Gaussian model. When the matrix X has more features than data points, d is larger than n, so it's a fat matrix. Assume we have some true parameter theta plot : Each element in this vector theta correspond to a feature from the input X. We use this theta and X to generate some data Y, and fit a linear Gaussian model using MLE. MLE is calculated with this closed-form solution and we can plot it on top of the two theta to compare. theta MLE adapts to reflect the quirks of training data and this estimate doesn't well generalize to other data, even sample from the same true model since noise doesn't repeatedly occur in any data sample. So one intuitive way of improving the parameter estimate is to suppress these large theta values. Thus L2 regularization, which is also known as Ridge regularization. It penalizes squared parameters and suppresses all features. We add a penalty term to the log-likelihood,  maximizing the log likelihood, will lead to minimizing the magnitude of theta i. But theta won't be minimized all the way to the zero. Because when theta is equal to zero, in my results, in a small likelihood term, the log of L. Thus the maximization is a balancing between these two terms. Beta is named as hyperparameter in regularization and with such a penalty term the estimate of theta will have smaller magnitude, thus, generalizes better. \n",
        "\n",
        "Mathematically if X has more columns than rows, which means the number of features in the input X is more than the number of data points. The covariance X transpose X is a low rank matrix now and adding this diagonal makes the matrix full rank. Thus, the inversion is more stable. Another popular regularization is L1 regularization, which is also known as Lasso regularization. Different from L2, it penalizes the absolute value of the parameters and thus, encourages sparse solutions. The L1 penalty pushes many features' weights to zero and effectively selects informative features. And we've thus mitigated the issue of more features than data samples by throwing away some features. The log likelihood of linear Gaussian with L1 penalty is very similar to L2 but L1 it doesn't have a closed form solution even for linear Gaussian model. The reason is the absolute value of theta is non-differentiable. Thus, we need optimization to fit the model. When we fit the model, we're talking about fitting for theta only, not include a hyperparameter beta. \n",
        "\n",
        "In practice, we need to select different beta values using cross-validation. \n",
        "- When beta is very small, the penalty term can be ignored. Thus the estimate looks very much like the MLE estimate.  \n",
        "- When beta is 0.1, all parameters are squashed with some zero values appearing. \n",
        "- When beta is ten, many parameters are squashed to zero and \n",
        "- when beta is a hundred most of the parameters are zero now. \n",
        "\n",
        "First, we need to use cross-validation to select which beta actually gives us the best estimate of parameters \n",
        "Similarly we can add L2 or L1 penalty to the log likelihood of logistic regression as well.\n",
        "\n",
        "Here - data fitting example for logistic regression plus L2 regularization. We have a binary classification problem. The output y is 1 or 0 and the input x is 2-dimensional. Thus, we have two weight coefficients, theta 1 and theta 2. We vary the hyperparameter, beta, from small to large shown in the x axis. We can see the magnitudes of these two coefficients decrease gradually all the way to 0 together. Thus there is no feature selection with L2 penalty. It doesn't prefer one over the other. We also plot the accuracy performance on the validation data given different beta values. We can see the accuracy increases a bit ,peaks at about beta is equal to 1, and then decreases as beta continues increasing. Then, based on this optimal beta value, the optimal theta1 and theta2 are picked with beta is equal to 1. Thus, without doing model evaluation on the validation data, it's really hard to figure out which data parameters are the best in practice. Because thetas are different, given different beta values. \n",
        "\n",
        "Here - another example for logistic regression plus L1 penalty. Still we have a binary classification problem. The main difference now is that the magnitudes of these two coefficients decrease to zero but not in a synchronous manner. Theta2 become zero earlier than theta1. Thus, after theta2 reaches zero, L1 achieves feature selection by throwing away the second feature. We also plot the accuracy performance on the test data given different beta values and we can see the accuracy increases a bit, peaks at beta is around 0.8 and then decreases as beta continues increasing. Then the optimal theta1 and theta2 are picked when beta is equal to 0.8 where theta1 is about 1.5 and theta2 is 0. Therefore, this solution is sparse. \n",
        "\n",
        "In the following notebook, you will see how the hyperparameter affects model fitting for logistic regression with L1 and L2 penalties. You will run cross validation to select the optimum hyperparameters beta for both L1 and L2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h93v7jpFtTyW"
      },
      "source": [
        "Regularization forces a model to learn a set of solutions you *a priori* believe to be more correct, which reduces overfitting because it doesn't have as much flexibility to fit idiosyncrasies in the training data. This adds model bias, but it's a good bias because you know (maybe) that parameters should be small or mostly 0.\n",
        "\n",
        "In a GLM, a common form of regularization is to *shrink* the classifier weights. In a linear model, you can see its effect by plotting the weights. We've defined a helper function, `plot_weights`, that we'll use extensively in this section.\n",
        "\n",
        "Here is what the weights look like for a Logistic Regression model with no regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9puOuF1ItTyW"
      },
      "source": [
        "log_reg = LogisticRegression(penalty=\"none\").fit(X, y)\n",
        "plot_weights({\"No regularization\": log_reg})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCvf0fnFtTyW"
      },
      "source": [
        "It's important to understand this plot. Each dot visualizes a value in our parameter vector $\\theta$. (It's the same style of plot as the one showing $\\theta$ in the video). Since each feature is the time-averaged response of a neuron, each dot shows how the model uses each neuron to estimate a decision.\n",
        "\n",
        "Note the scale of the y-axis. Some neurons have values of about $20$, whereas others scale to $-20$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuVqJO7gtTyW"
      },
      "source": [
        "## Section 3.1: $L_2$ regularization\n",
        "\n",
        "Regularization comes in different flavors. A very common one uses an $L_2$ or \"ridge\" penalty. This changes the objective function to\n",
        "\n",
        "$$-\\log\\mathcal{L}'(\\theta | X, y)=\n",
        "-\\log\\mathcal{L}(\\theta | X, y) +\\frac\\beta2\\sum_i\\theta_i^2,\n",
        "$$\n",
        "\n",
        "where $\\beta$ is a *hyperparameter* that sets the *strength* of the regularization.\n",
        "\n",
        "You can use regularization in `scikit-learn` by changing the `penalty`, and you can set the strength of the regularization with the `C` hyperparameter ($C = \\frac{1}{\\beta}$, so this sets the *inverse* regularization).\n",
        "\n",
        "Let's compare the unregularized classifier weights with the classifier weights when we use the default `C = 1`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-a7z3QttTyW"
      },
      "source": [
        "log_reg_l2 = LogisticRegression(penalty=\"l2\", C=1).fit(X, y)\n",
        "\n",
        "# now show the two models\n",
        "models = {\n",
        "  \"No regularization\": log_reg,\n",
        "  \"$L_2$ (C = 1)\": log_reg_l2,\n",
        "}\n",
        "plot_weights(models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML-br6FmtTyW"
      },
      "source": [
        "Using the same scale for the two y axes, it's almost impossible to see the $L_2$ weights. Let's allow the y axis scales to adjust to each set of weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wBK5rK3tTyX"
      },
      "source": [
        "plot_weights(models, sharey=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18bcs6OstTyX"
      },
      "source": [
        "\n",
        "Now you can see that the weights have the same basic pattern, but the regularized weights are an order-of-magnitude smaller.\n",
        "\n",
        "### Interactive Demo: The effect of varying C on parameter size\n",
        "\n",
        "We can use this same approach to see how the weights depend on the *strength* of the regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-TMhkMMmtTyX"
      },
      "source": [
        "#@title\n",
        "\n",
        "#@markdown Execute this cell to enable the widget!\n",
        "\n",
        "# Precompute the models so the widget is responsive\n",
        "log_C_steps = 1, 10, 1\n",
        "penalized_models = {}\n",
        "for log_C in np.arange(*log_C_steps, dtype=int):\n",
        "  m = LogisticRegression(\"l2\", C=10 ** log_C, max_iter=5000)\n",
        "  penalized_models[log_C] = m.fit(X, y)\n",
        "\n",
        "@widgets.interact\n",
        "def plot_observed(log_C=log_C_steps):\n",
        "  models = {\n",
        "    \"No regularization\": log_reg,\n",
        "    f\"$L_2$ (C = $10^{log_C}$)\": penalized_models[log_C]\n",
        "  }\n",
        "  plot_weights(models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTY9j06PtTyX"
      },
      "source": [
        "Recall from above that $C=\\frac1\\beta$ so larger `C` is less regularization. The top panel corresponds to $C=\\infty$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c70bfJDztTyX"
      },
      "source": [
        "## Section 3.2: $L_1$ regularization\n",
        "\n",
        "$L_2$ is not the only option for regularization. There is also the $L_1$, or \"Lasso\" penalty. This changes the objective function to\n",
        "\n",
        "$$\n",
        "-\\log\\mathcal{L}'(\\theta | X, y)=\n",
        "-\\log\\mathcal{L}(\\theta | X, y) +\\frac\\beta2\\sum_i|\\theta_i|\n",
        "$$\n",
        "\n",
        "In practice, using the summed absolute values of the weights causes *sparsity*: instead of just getting smaller, some of the weights will get forced to $0$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJOpl1LtTyX"
      },
      "source": [
        "log_reg_l1 = LogisticRegression(penalty=\"l1\", C=1, solver=\"saga\", max_iter=5000)\n",
        "log_reg_l1.fit(X, y)\n",
        "models = {\n",
        "  \"$L_2$ (C = 1)\": log_reg_l2,\n",
        "  \"$L_1$ (C = 1)\": log_reg_l1,\n",
        "}\n",
        "plot_weights(models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsZHOj4EtTyX"
      },
      "source": [
        "Note: You'll notice that we added two additional parameters: `solver=\"saga\"` and `max_iter=5000`. The `LogisticRegression` class can use several different optimization algorithms (\"solvers\"), and not all of them support the $L_1$ penalty. At a certain point, the solver will give up if it hasn't found a minimum value. The `max_iter` parameter tells it to make more attempts; otherwise, we'd see an ugly warning about \"convergence\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-yN4GputTyY"
      },
      "source": [
        "# Section 4: The key difference between $L_1$ and $L_2$ regularization: sparsity\n",
        "\n",
        "When should you use $L_1$ vs. $L_2$ regularization? Both penalties shrink parameters, and both will help reduce overfitting. However, the models they lead to are different. \n",
        "\n",
        "In particular, the $L_1$ penalty encourages *sparse* solutions in which most parameters are 0. Let's unpack the notion of sparsity.\n",
        "\n",
        "A \"dense\" vector has mostly nonzero elements:\n",
        "$\\begin{bmatrix}\n",
        "  0.1 \\\\ -0.6\\\\-9.1\\\\0.07 \n",
        "\\end{bmatrix}$. \n",
        "A \"sparse\" vector has mostly zero elements:\n",
        "$\\begin{bmatrix}\n",
        "  0 \\\\ -0.7\\\\ 0\\\\0\n",
        "\\end{bmatrix}$.\n",
        "\n",
        "The same is true of matrices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KGuH53gjtTyY"
      },
      "source": [
        "#@title\n",
        "#@markdown Execute to plot a dense and a sparse matrix\n",
        "np.random.seed(50)\n",
        "n = 5\n",
        "M = np.random.random((n, n))\n",
        "M_sparse = np.random.choice([0,1], size=(n, n), p=[0.8, 0.2])\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10,5))\n",
        "\n",
        "axs[0].imshow(M)\n",
        "axs[1].imshow(M_sparse)\n",
        "axs[0].axis('off')\n",
        "axs[1].axis('off')\n",
        "axs[0].set_title(\"A dense matrix\", fontsize=15)\n",
        "axs[1].set_title(\"A sparse matrix\", fontsize=15)\n",
        "text_kws = dict(ha=\"center\", va=\"center\")\n",
        "for i in range(n):\n",
        "  for j in range(n):\n",
        "    iter_parts = axs, [M, M_sparse], [\"{:.1f}\", \"{:d}\"]\n",
        "    for ax, mat, fmt in zip(*iter_parts):\n",
        "      val = mat[i, j]\n",
        "      color = \".1\" if val > .7 else \"w\"\n",
        "      ax.text(j, i, fmt.format(val), c=color, **text_kws)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kMzQb3CtTyZ"
      },
      "source": [
        "## Exercise 3: The effect of $L_1$ regularization on parameter sparsity\n",
        "\n",
        "Please complete the following function to fit a regularized `LogisticRegression` model and return **the number of coefficients in the parameter vector that are equal to 0**.\n",
        "\n",
        "Don't forget to check out the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlOgXV4QtTyZ"
      },
      "source": [
        "def count_non_zero_coefs(X, y, C_values):\n",
        "  \"\"\"Fit models with different L1 penalty values and count non-zero coefficients.\n",
        "\n",
        "  Args:\n",
        "    X (2D array): Data matrix\n",
        "    y (1D array): Label vector\n",
        "    C_values (1D array): List of hyperparameter values\n",
        "\n",
        "  Returns:\n",
        "    non_zero_coefs (list): number of coefficients in each model that are nonzero\n",
        "\n",
        "  \"\"\"\n",
        "  #############################################################################\n",
        "  # TODO Complete the function and remove the error\n",
        "  raise NotImplementedError(\"Implement the count_non_zero_coefs function\")\n",
        "  #############################################################################\n",
        "\n",
        "  non_zero_coefs = []\n",
        "  for C in C_values:\n",
        "\n",
        "    # Initialize and fit the model\n",
        "    # (Hint, you may need to set max_iter)\n",
        "    model = ...\n",
        "    ...\n",
        "\n",
        "    # Get the coefs of the fit model\n",
        "    coefs = ...\n",
        "\n",
        "    # Count the number of non-zero elements in coefs\n",
        "    non_zero = ...\n",
        "    non_zero_coefs.append(non_zero)\n",
        "\n",
        "  return non_zero_coefs\n",
        "\n",
        "# Use log-spaced values for C\n",
        "C_values = np.logspace(-4, 4, 5)\n",
        "\n",
        "# Uncomment and run when the function is ready for testing\n",
        "# non_zero_l1 = count_non_zero_coefs(X, y, C_values)\n",
        "# plot_non_zero_coefs(C_values, non_zero_l1, n_voxels=X.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Snl5_UtTyZ"
      },
      "source": [
        "# to_remove solution\n",
        "def count_non_zero_coefs(X, y, C_values):\n",
        "  \"\"\"Fit models with different L1 penalty values and count non-zero coefficients.\n",
        "\n",
        "  Args:\n",
        "    X (2D array): Data matrix\n",
        "    y (1D array): Label vector\n",
        "    C_values (1D array): List of hyperparameter values\n",
        "\n",
        "  Returns:\n",
        "    non_zero_coefs (list): number of coefficients in each model that are nonzero\n",
        "\n",
        "  \"\"\"\n",
        "  non_zero_coefs = []\n",
        "  for C in C_values:\n",
        "\n",
        "    # Initialize and fit the model\n",
        "    # (Hint, you may need to set max_iter)\n",
        "    model = LogisticRegression(penalty=\"l1\", C=C, solver=\"saga\", max_iter=5000)\n",
        "    model.fit(X,y)\n",
        "\n",
        "    # Get the coefs of the fit model\n",
        "    coefs = model.coef_\n",
        "\n",
        "    # Count the number of non-zero elements in coefs\n",
        "    non_zero = np.sum(coefs != 0)\n",
        "    non_zero_coefs.append(non_zero)\n",
        "\n",
        "  return non_zero_coefs\n",
        "\n",
        "# Use log-spaced values for C\n",
        "C_values = np.logspace(-4, 4, 5)\n",
        "\n",
        "non_zero_l1 = count_non_zero_coefs(X, y, C_values)\n",
        "\n",
        "with plt.xkcd():\n",
        "  plot_non_zero_coefs(C_values, non_zero_l1, n_voxels=X.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH1dkasqtTyZ"
      },
      "source": [
        "Smaller `C` (bigger $\\beta$) leads to sparser solutions.\n",
        "\n",
        "**Link to neuroscience**: When is it OK to assume that the parameter vector is sparse? Whenever it is true that most features don't affect the outcome. One use-case might be decoding low-level visual features from whole-brain fMRI: we may expect only voxels in V1 and thalamus should be used in the prediction.\n",
        "\n",
        "**WARNING**: be careful when interpreting $\\theta$. Never interpret the nonzero coefficients as *evidence* that only those voxels/neurons/features carry information about the outcome. This is a product of our regularization scheme, and thus *our prior assumption that the solution is sparse*. Other regularization types or models may find very distributed relationships across the brain. Never use a model as evidence for a phenomena when that phenomena is encoded in the assumptions of the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQKY7DtTtTyZ"
      },
      "source": [
        "---\n",
        "\n",
        "## Section 4.1: Choosing the regularization penalty\n",
        "\n",
        "In the examples above, we just picked arbitrary numbers for the strength of regularization. How do you know what value of the hyperparameter to use?\n",
        "\n",
        "The answer is the same as when you want to know whether you have learned good parameter values: use cross-validation. The best hyperparameter will be the one that allows the model to generalize best to unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XTCrm-2tTyZ"
      },
      "source": [
        "### Exercise 4: Model selection\n",
        "\n",
        "In the final exercise, we will use cross-validation to evaluate a set of models, each with a different $L_2$ penalty. Your `model_selection` function should have a for-loop that gets the mean cross-validated accuracy for each penalty value (use the `cross_val_score` function that we introduced above)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcygjJhZtTya"
      },
      "source": [
        "def model_selection(X, y, C_values):\n",
        "  \"\"\"Compute CV accuracy for each C value.\n",
        "\n",
        "  Args:\n",
        "    X (2D array): Data matrix\n",
        "    y (1D array): Label vector\n",
        "    C_values (1D array): Array of hyperparameter values\n",
        "\n",
        "  Returns:\n",
        "    accuracies (1D array): CV accuracy with each value of C\n",
        "\n",
        "  \"\"\"\n",
        "  #############################################################################\n",
        "  # TODO Complete the function and remove the error\n",
        "  raise NotImplementedError(\"Implement the model_selection function\")\n",
        "  #############################################################################\n",
        "\n",
        "  accuracies = []\n",
        "  for C in C_values:\n",
        "\n",
        "    # Initialize and fit the model\n",
        "    # (Hint, you may need to set max_iter)\n",
        "    model = ...\n",
        "\n",
        "    # Get the accuracy for each test split\n",
        "    accs = ...\n",
        "\n",
        "    # Store the average test accuracy for this value of C\n",
        "    accuracies.append(...)\n",
        "\n",
        "  return accuracies\n",
        "\n",
        "# Use log-spaced values for C\n",
        "C_values = np.logspace(-4, 4, 9)\n",
        "\n",
        "# Uncomment and run when the function is ready to test\n",
        "# accuracies = model_selection(X, y, C_values)\n",
        "# plot_model_selection(C_values, accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gefy9txtTya"
      },
      "source": [
        "# to_remove solution\n",
        "def model_selection(X, y, C_values):\n",
        "  \"\"\"Compute CV accuracy for each C value.\n",
        "\n",
        "  Args:\n",
        "    X (2D array): Data matrix\n",
        "    y (1D array): Label vector\n",
        "    C_values (1D array): Array of hyperparameter values.\n",
        "\n",
        "  Returns:\n",
        "    accuracies (1D array): CV accuracy with each value of C.\n",
        "\n",
        "  \"\"\"\n",
        "  accuracies = []\n",
        "  for C in C_values:\n",
        "\n",
        "    # Initialize and fit the model\n",
        "    # (Hint, you may need to set max_iter)\n",
        "    model = LogisticRegression(penalty=\"l2\", C=C, max_iter=5000)\n",
        "\n",
        "    # Get the accuracy for each test split\n",
        "    accs = cross_val_score(model, X, y, cv=8)\n",
        "\n",
        "    # Store the average test accuracy for this value of C\n",
        "    accuracies.append(accs.mean())\n",
        "\n",
        "  return accuracies\n",
        "\n",
        "# Use log-spaced values for C\n",
        "C_values = np.logspace(-4, 4, 9)\n",
        "\n",
        "accuracies = model_selection(X, y, C_values)\n",
        "with plt.xkcd():\n",
        "  plot_model_selection(C_values, accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLnZ37OwtTya"
      },
      "source": [
        "This plot suggests that the right value of $C$ does matter â€” up to a point. Remember that C is the *inverse* regularization. The plot shows that models where the regularization was too strong (small C values) performed very poorly. For $C > 10^{-2}$, the differences are marginal, but the best performance was obtained with an intermediate value ($C \\approx 10^1$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPxdntPKtTya"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In this notebook, we learned about Logistic Regression, a fundamental algorithm for *classification*. We applied the algorithm to a *neural decoding* problem: we tried to predict an animal's behavioral choice from its neural activity. We saw again how important it is to use *cross-validation* to evaluate complex models that are at risk for *overfitting*, and we learned how *regularization* can be used to fit models that generalize better. Finally, we learned about some of the different options for regularization, and we saw how cross-validation can be useful for *model selection*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD7bpiM3tTya"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZTHn2tTtTya"
      },
      "source": [
        "# Appendix: The Logistic Regression model in full\n",
        "\n",
        "The fundamental input/output equation of logistic regression is:\n",
        "\n",
        "$$p(y_i = 1 |x_i, \\theta) = \\sigma(\\theta^Tx_i)$$\n",
        "\n",
        "## The logistic link function\n",
        "\n",
        "You've seen $\\theta^T x_i$ before, but the $\\sigma$ is new. It's the *sigmoidal* or *logistic* link function that \"squashes\" $\\theta^T x_i$ to keep it between $0$ and $1$:\n",
        "\n",
        "$$\\sigma(z) = \\frac{1}{1 + \\textrm{exp}(-z)}$$\n",
        "\n",
        "## The Bernoulli likelihood\n",
        "\n",
        "You might have noticed that the output of the sigmoid, $\\hat{y}$ is not a binary value (0 or 1), even though the true data $y$ is! Instead, we interpret the value of $\\hat{y}$ as the *probability that y = 1*:\n",
        "\n",
        "$$ \\hat{y_i} \\equiv p(y_i=1|x_i,\\theta) = \\frac{1}{{1 + \\textrm{exp}(-\\theta^Tx_i)}}$$\n",
        "\n",
        "To get the likelihood of the parameters, we need to define *the probability of seeing $y$ given $\\hat{y}$*. In logistic regression, we do this using the Bernoulli distribution:\n",
        "\n",
        "$$P(y_i\\ |\\ \\hat{y}_i) = \\hat{y}_i^{y_i}(1 - \\hat{y}_i)^{(1 - y_i)}$$\n",
        "\n",
        "So plugging in the regression model:\n",
        "\n",
        "$$P(y_i\\ |\\ \\theta, x_i) = \\sigma(\\theta^Tx_i)^{y_i}(1 - \\sigma(\\theta^Tx_i))^{(1 - y_i)}.$$\n",
        "\n",
        "This expression effectively measures how good our parameters $\\theta$ are. We can also write it as the likelihood of the parameters given the data:\n",
        "\n",
        "$$\\mathcal{L}(\\theta\\ |\\ y_i, x_i) = P(y_i\\ |\\ \\theta, x_i),$$\n",
        "\n",
        "and then use this as a target of optimization, considering all of the trials independently:\n",
        "\n",
        "$$\\textrm{log}\\mathcal{L}(\\theta | X, y) = \\sum_{i=1}^Ny_i\\textrm{log}(\\sigma(\\theta^Tx_i))\\ +\\ (1-y_i)\\textrm{log}(1 - \\sigma(\\theta^Tx_i)).$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0N39bn_tTyb"
      },
      "source": [
        "# Appendix: More detail about model selection\n",
        "\n",
        "In the final exercise, we used all of the data to choose the hyperparameters. That means we don't have any fresh data left over to evaluate the performance of the selected model. In practice, you would want to have two *nested* layers of cross-validation, where the final evaluation is performed on data that played no role in selecting or training the model.\n",
        "\n",
        "Indeed, the proper method for splitting your data to choose hyperparameters can get confusing. Here's a guide that the authors of this notebook developed while writing a tutorial on using machine learning for neural decoding (https://arxiv.org/abs/1708.00909).\n",
        "\n",
        "<img src='http://kordinglab.com/images/others/CV-01.png' width= '700'/>\n"
      ]
    }
  ]
}