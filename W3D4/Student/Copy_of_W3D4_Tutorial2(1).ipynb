{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of W3D4_Tutorial2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnwykDyWO-JP"
      },
      "source": [
        "# Neuromatch Academy: Week 3, Day 4, Tutorial 2\n",
        "# Deep Learning: Encoding Neural Responses\n",
        "\n",
        "**Content creators**: Jorge A. Menendez, Carsen Stringer \n",
        "\n",
        "**Content reviewers**: Roozbeh Farhoodi, Ella Batty, Kshitij Dwivedi, Spiros Chavlis, Michael Waskom\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEuOx8U6O-JY"
      },
      "source": [
        "---\n",
        "#Tutorial Objectives\n",
        "\n",
        "In this tutorial, we'll use deep learning to build an encoding model from stimuli to neural activity. Specifically, we'll be looking at the activity of ~20,000 neurons in mouse primary visual cortex responding to oriented gratings recorded in [this study](https://www.biorxiv.org/content/10.1101/679324v2.abstract). \n",
        "\n",
        "Because the stimuli are 1D and the neurons respond with smooth tuning curves, we will model the neural responses as a 1D convolutional operation on the stimulus. \n",
        "\n",
        "In this tutorial, we will \n",
        "* Understand the basics of convolution\n",
        "* Build and train a convolutional neural network to predict neural responses using PyTorch\n",
        "* Visualize and analyze its internal representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHGAoDxGO-JY"
      },
      "source": [
        "---\n",
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "Fy5w3LcEO-JZ"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Z-aXMbDIO-Ja"
      },
      "source": [
        "#@title Figure settings\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "qPxpnTjPO-Jb"
      },
      "source": [
        "#@title Data retrieval and loading\n",
        "import hashlib\n",
        "import requests\n",
        "\n",
        "fname = \"W3D4_stringer_oribinned6_split.npz\"\n",
        "url = \"https://osf.io/p3aeb/download\"\n",
        "expected_md5 = \"b3f7245c6221234a676b71a1f43c3bb5\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    elif hashlib.md5(r.content).hexdigest() != expected_md5:\n",
        "      print(\"!!! Data download appears corrupted !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEGuMhojO-Jc"
      },
      "source": [
        "#@title Helper Functions\n",
        "# Some helper functions\n",
        "def load_data_split(data_name=fname):\n",
        "  \"\"\"Load mouse V1 data from Stringer et al. (2019)\n",
        "\n",
        "  Data from study reported in this preprint:\n",
        "  https://www.biorxiv.org/content/10.1101/679324v2.abstract\n",
        "\n",
        "  These data comprise time-averaged responses of ~20,000 neurons\n",
        "  to ~4,000 stimulus gratings of different orientations, recorded\n",
        "  through Calcium imaging. The responses have been normalized by\n",
        "  spontaneous levels of activity and then z-scored over stimuli, so\n",
        "  expect negative numbers. The repsonses were split into train and\n",
        "  test and then each set were averaged in bins of 6 degrees.\n",
        "\n",
        "  This function returns the relevant data (neural responses and\n",
        "  stimulus orientations) in a torch.Tensor of data type torch.float32\n",
        "  in order to match the default data type for nn.Parameters in\n",
        "  Google Colab.\n",
        "\n",
        "  It will hold out some of the trials when averaging to allow us to have test\n",
        "  tuning curves.\n",
        "\n",
        "  Args:\n",
        "    data_name (str): filename to load\n",
        "\n",
        "  Returns:\n",
        "    resp_train (torch.Tensor): n_stimuli x n_neurons matrix of neural responses,\n",
        "        each row contains the responses of each neuron to a given stimulus.\n",
        "        As mentioned above, neural \"response\" is actually an average over\n",
        "        responses to stimuli with similar angles falling within specified bins.\n",
        "    resp_test (torch.Tensor): n_stimuli x n_neurons matrix of neural responses,\n",
        "        each row contains the responses of each neuron to a given stimulus.\n",
        "        As mentioned above, neural \"response\" is actually an average over\n",
        "        responses to stimuli with similar angles falling within specified bins\n",
        "    stimuli: (torch.Tensor): n_stimuli x 1 column vector with orientation\n",
        "        of each stimulus, in degrees. This is actually the mean orientation\n",
        "        of all stimuli in each bin.\n",
        "\n",
        "  \"\"\"\n",
        "  with np.load(data_name) as dobj:\n",
        "    data = dict(**dobj)\n",
        "  resp_train = data['resp_train']\n",
        "  resp_test = data['resp_test']\n",
        "  stimuli = data['stimuli']\n",
        "\n",
        "  # Return as torch.Tensor\n",
        "  resp_train_tensor = torch.tensor(resp_train, dtype=torch.float32)\n",
        "  resp_test_tensor = torch.tensor(resp_test, dtype=torch.float32)\n",
        "  stimuli_tensor = torch.tensor(stimuli, dtype=torch.float32)\n",
        "\n",
        "  return resp_train_tensor, resp_test_tensor, stimuli_tensor\n",
        "\n",
        "\n",
        "def plot_tuning(ax, stimuli, respi_train, respi_test, neuron_index, linewidth=2):\n",
        "  \"\"\"Plot the tuning curve of a neuron\"\"\"\n",
        "\n",
        "  ax.plot(stimuli, respi_train, 'y', linewidth=linewidth)  # plot its responses as a function of stimulus orientation\n",
        "  ax.plot(stimuli, respi_test, 'm', linewidth=linewidth)  # plot its responses as a function of stimulus orientation\n",
        "  ax.set_title('neuron %i' % neuron_index)\n",
        "  ax.set_xlabel('stimulus orientation ($^o$)')\n",
        "  ax.set_ylabel('neural response')\n",
        "  ax.set_xticks(np.linspace(0, 360, 5))\n",
        "  ax.set_ylim([-0.5, 2.4])\n",
        "\n",
        "\n",
        "# from bayes day!\n",
        "def my_gaussian(x_points, mu, sigma):\n",
        "  \"\"\"\n",
        "  Returns normalized Gaussian estimated at points `x_points`, with parameters: mean `mu` and std `sigma`\n",
        "\n",
        "  Args:\n",
        "    x_points (numpy array of floats): points at which the gaussian is evaluated\n",
        "    mu (scalar): mean of the Gaussian\n",
        "    sigma (scalar): std of the gaussian\n",
        "\n",
        "  Returns:\n",
        "    (numpy array of floats) : un-normalized Gaussian (i.e. without constant) evaluated at `x`\n",
        "  \"\"\"\n",
        "  px = np.exp(- 1/2/sigma**2 * (mu - x_points) ** 2)\n",
        "  px = px / px.sum()\n",
        "  return px\n",
        "\n",
        "\n",
        "def plot_conv(pad, stimulus, filter, conv_out):\n",
        "  \"\"\" plot 1D convolution \"\"\"\n",
        "  # plot stimulus\n",
        "  ax = fig.add_subplot(1,3,1)\n",
        "  ax.plot(np.arange(0, 360), stimulus, 'k')\n",
        "  ax.set_title('stimulus')\n",
        "  ax.set_xlabel('orientation ($^o$)')\n",
        "  ax.set_ylabel('stimulus')\n",
        "\n",
        "  # plot convolutional filter\n",
        "  ax = fig.add_subplot(1,3,2)\n",
        "  ax.plot(np.arange(-pad, pad), filter)\n",
        "  ax.set_xlabel('orientation ($^o$)')\n",
        "  ax.set_ylabel('magnitude')\n",
        "  ax.set_title('convolutional filter')\n",
        "\n",
        "  # plot convolutional output\n",
        "  ax = fig.add_subplot(1,3,3)\n",
        "  n_units = (~np.isnan(conv_out)).sum()\n",
        "  ax.scatter(np.arange(0,n_units),\n",
        "             conv_out[~np.isnan(conv_out)], s=30,\n",
        "             cmap='hsv', c=np.arange(0,n_units))\n",
        "  ax.set_xlabel('convolutional unit')\n",
        "  ax.set_ylabel('activation')\n",
        "  ax.set_title('activations of\\nconvolutional units')\n",
        "\n",
        "\n",
        "def plot_example_activations(act):\n",
        "  \"\"\" plot activations act and corresponding stimulus\n",
        "  Args:\n",
        "        act: activations of convolutional layer (n_bins x conv_channels x n_bins)\n",
        "  \"\"\"\n",
        "  ns = [10,25,40]\n",
        "  fig, axs = plt.subplots(1,3,figsize=(12,4))\n",
        "  for k, (n, ax) in enumerate(zip(ns, axs.flatten())):\n",
        "    ax.plot(n * np.ones(2), [act.min()*1.15, act.max()*1.15], 'k', linewidth=4)\n",
        "    ax.plot(act[n].T, '.', linewidth=2)\n",
        "    ax.set_xlabel('convolutional unit')\n",
        "    ax.set_ylabel('activation')\n",
        "    ax.set_title('stim id %d'%n)\n",
        "    leg = ['chan%d'%i for i in range(act.shape[1])]\n",
        "    leg.insert(0, 'stim')\n",
        "    n_units = act.shape[0]\n",
        "    for k,s in enumerate(leg):\n",
        "      if k==0:\n",
        "        ax.text(((n+15)%n_units)/n_units, .9-k*.1, s, transform=ax.transAxes, color='k', ha='center')\n",
        "      else:\n",
        "        ax.text(((n+15)%n_units)/n_units, .9-k*.1, s, transform=ax.transAxes, color='C%d'%(k-1), ha='center')\n",
        "\n",
        "\n",
        "def train(net, custom_loss, train_data, train_labels,\n",
        "          test_data=None, test_labels=None,\n",
        "          learning_rate=10, n_iter=500, L2_penalty=0., L1_penalty=0.):\n",
        "  \"\"\"Run gradient descent for network without batches\n",
        "\n",
        "  Args:\n",
        "    net (nn.Module): deep network whose parameters to optimize with SGD\n",
        "    custom_loss: loss function for network\n",
        "    train_data: training data (n_train x input features)\n",
        "    train_labels: training labels (n_train x output features)\n",
        "    test_data: test data (n_train x input features)\n",
        "    test_labels: test labels (n_train x output features)\n",
        "    learning_rate (float): learning rate for gradient descent\n",
        "    n_epochs (int): number of epochs to run gradient descent\n",
        "    L2_penalty (float): magnitude of L2 penalty\n",
        "    L1_penalty (float): magnitude of L1 penalty\n",
        "\n",
        "  Returns:\n",
        "    train_loss: training loss across iterations\n",
        "    test_loss: testing loss across iterations\n",
        "\n",
        "  \"\"\"\n",
        "  optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.5) # Initialize PyTorch SGD optimizer\n",
        "  train_loss = np.nan * np.zeros(n_iter)  # Placeholder for train loss\n",
        "  test_loss = np.nan * np.zeros(n_iter)  # Placeholder for test loss\n",
        "\n",
        "  # Loop over epochs\n",
        "  for i in range(n_iter):\n",
        "    y_pred = net(train_data) # Forward pass: compute predicted y by passing train_data to the model.\n",
        "\n",
        "    if L2_penalty>0 or L1_penalty>0:\n",
        "      weights = net.out_layer.weight\n",
        "      loss = custom_loss(y_pred, train_labels, weights, L2_penalty, L1_penalty)\n",
        "    else:\n",
        "      loss = custom_loss(y_pred, train_labels)\n",
        "\n",
        "    ### Update parameters\n",
        "    optimizer.zero_grad() # zero out gradients\n",
        "    loss.backward() # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "    optimizer.step() # step parameters in gradient direction\n",
        "    train_loss[i] = loss.item()  # .item() transforms the tensor to a scalar and does .detach() for us\n",
        "\n",
        "    # Track progress\n",
        "    if (i+1) % (n_iter // 10) == 0 or i==0:\n",
        "      if test_data is not None and test_labels is not None:\n",
        "        y_pred = net(test_data)\n",
        "        if L2_penalty>0 or L1_penalty>0:\n",
        "          loss = custom_loss(y_pred, test_labels, weights, L2_penalty, L1_penalty)\n",
        "        else:\n",
        "          loss = custom_loss(y_pred, test_labels)\n",
        "        test_loss[i] = loss.item()\n",
        "        print(f'iteration {i+1}/{n_iter} | train loss: {train_loss[i]:.4f} | test loss: {test_loss[i]:.4f}')\n",
        "      else:\n",
        "        print(f'iteration {i+1}/{n_iter} | train loss: {train_loss[i]:.4f}')\n",
        "\n",
        "  return train_loss, test_loss\n",
        "\n",
        "\n",
        "def plot_pred_weights(y_pred, y_train, y_test, weights):\n",
        "  \"\"\" plot example neural response prediction + weights \"\"\"\n",
        "  fig = plt.figure(figsize=(12,4))\n",
        "  ax =fig.add_subplot(1,3,1)\n",
        "  ax.plot(y_train, 'y', linewidth=1)\n",
        "  ax.plot(y_test, 'm', linewidth=1)\n",
        "  ax.plot(y_pred, 'g', linestyle='-', linewidth=3)\n",
        "  ax.set_xlabel('stimulus bin')\n",
        "  ax.set_ylabel('response')\n",
        "  ax.text(0.1, 1.0, 'train', color='y', transform=ax.transAxes)\n",
        "  ax.text(0.1, 0.9, 'test', color='m', transform=ax.transAxes)\n",
        "  ax.text(0.1, 0.8, 'pred', color='g', transform=ax.transAxes)\n",
        "\n",
        "  ax=fig.add_subplot(1,3,2)\n",
        "  ax.plot(y_train, y_train, 'k', lw=1)\n",
        "  ax.scatter(y_train, y_pred, s=8, color='y')\n",
        "  ax.scatter(y_test, y_pred, s=8, color='m')\n",
        "  ax.set_xlabel('neural response')\n",
        "  ax.set_ylabel('predicted response', color='g')\n",
        "  ax.text(0.1, 1.0, 'train', color='y', transform=ax.transAxes)\n",
        "  ax.text(0.1, 0.9, 'test', color='m', transform=ax.transAxes)\n",
        "  plt.axis('square')\n",
        "\n",
        "  ### plot weights of fully-connected layer for first 300 neurons\n",
        "  plt.subplot(1,3,3)\n",
        "  plt.imshow(weights, aspect='auto', cmap='bwr', vmin=-0.01,vmax=0.01)\n",
        "  plt.title('out_layer weights')\n",
        "  plt.ylabel('neurons')\n",
        "  plt.xlabel('convolutional units')\n",
        "  plt.colorbar()\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_prediction(ax, y_pred, y_test):\n",
        "  \"\"\" plot prediction of neural response + test neural response \"\"\"\n",
        "  ax.plot(y_test,color='m')\n",
        "  ax.plot(y_pred, 'g', linewidth=3)\n",
        "  ax.set_xlabel('stimulus bin')\n",
        "  ax.set_ylabel('response')\n",
        "\n",
        "\n",
        "def plot_training_curves(train_loss, test_loss):\n",
        "  f, ax = plt.subplots()\n",
        "  ax.plot(train_loss, 'y', label=\"Train loss\")\n",
        "  ax.plot(test_loss, '.', markersize=10, color='m', label=\"Test loss\")\n",
        "  ax.set(xlabel=\"Gradient descent iteration\", ylabel=\"Mean squared error\")\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLOixPzxVlfv"
      },
      "source": [
        "# Summary of Helper functions:\n",
        "\n",
        "*load_data*: Load mouse V1 data from Stringer et al. (2019)\n",
        "\n",
        "    These data comprise time-averaged responses of ~20,000 neurons\n",
        "    to ~4,000 stimulus gratings of different orientations, recorded\n",
        "    through Calcium imaginge. The responses have been normalized by\n",
        "    spontanous levels of activity and then z-scored over stimuli, so\n",
        "    expect negative numbers. They have also been binned and averaged\n",
        "    to each degree of orientation.\n",
        "\n",
        "    This function returns the relevant data (neural responses and\n",
        "    stimulus orientations) in a torch.Tensor of data type torch.float32\n",
        "    in order to match the default data type for nn.Parameters in\n",
        "    Google Colab.\n",
        "\n",
        "    This function will actually average responses to stimuli with orientations\n",
        "    falling within bins specified by the bin_width argument. This helps\n",
        "    produce individual neural \"responses\" with smoother and more\n",
        "    interpretable tuning curves.\n",
        "\n",
        "*plot_tuning(ax, stimuli, respi_train, respi_test, neuron_index, linewidth=2)*: \"Plot the tuning curve of a neuron i.e., stimulus orientation (xaxis) vs neural response (yaxis)\n",
        "\n",
        "*my_gaussian*: Returns normalized Gaussian estimated at points `x_points`, with parameters: mean `mu` and std `sigma`\n",
        "\n",
        "*plot_conv(pad, stimulus, filter, conv_out)*: plot 1D convolution\n",
        "- Stimulus: orientation (xaxis) vs stimulus (yaxis)\n",
        "- Convolution filter: orientation (xaxis) vs magnitude (yaxis)\n",
        "- Convolutional unit output/ Activations of convolution units: convolution unit (xaxis) vs activation (yaxis)\n",
        "\n",
        "*plot_example_activations(act)*: plot activations act and corresponding stimulus\n",
        "\n",
        "*train(net, custom_loss, train_data, train_labels,\n",
        "          test_data=None, test_labels=None,\n",
        "          learning_rate=10, n_iter=500, L2_penalty=0., L1_penalty=0.)*: Run gradient descent for network without batches; loop over epochs - forward pass / update parameters / backward progress / track progress\n",
        "\n",
        "*plot_pred_weights(y_pred, y_train, y_test, weights)*: plot example neural response prediction + weights; \n",
        "- stimulus bin (xaxis) vs response (yaxis)\n",
        "- neural response (xaxis) vs predicted response (yaxis)\n",
        "- for out_layer weights, neurons (yaxis) vs convolutional units (xaxis)\n",
        "\n",
        "*plot_prediction(ax, y_pred, y_test)*: plot prediction of neural response + test neural response\n",
        "\n",
        "*plot_training_curves(train_loss, test_loss)*: gradient descent iteration (xaxis) vs mean squared error (yaxis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZZ1lQsjO-Jc"
      },
      "source": [
        "---\n",
        "# Section 1: Neural Tuning Curves\n",
        "\n",
        "In the next cell, we plot the turning curves of a random subset of neurons. We have binned the stimuli orientations more than in Tutorial 1. \n",
        "\n",
        "Rerun the cell to look at different example neurons and observe the diversity of tuning curves in the population. How can we fit these neural responses with an encoding model?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "cqJM8NeaO-Jd"
      },
      "source": [
        "#@title\n",
        "#@markdown Execute this cell to load data and plot neural tuning curves\n",
        "\n",
        "### Load data and bin at 8 degrees\n",
        "# responses are split into test and train\n",
        "resp_train, resp_test, stimuli = load_data_split()\n",
        "n_stimuli, n_neurons = resp_train.shape\n",
        "print('resp_train contains averaged responses of %i neurons to %i binned stimuli' % (n_neurons, n_stimuli))\n",
        "#print(resp_train.shape)\n",
        "\n",
        "# also make stimuli into array of 0's and 1's\n",
        "n_bins = len(stimuli)\n",
        "stim_binary = torch.eye(n_bins, dtype=torch.float32)\n",
        "\n",
        "# Visualize tuning curves\n",
        "fig, axs = plt.subplots(3, 5, figsize=(15,7))\n",
        "for k, ax in enumerate(axs.flatten()):\n",
        "  neuron_index = np.random.choice(n_neurons)  # pick random neuron\n",
        "  plot_tuning(ax, stimuli, resp_train[:, neuron_index], resp_test[:, neuron_index], neuron_index, linewidth=2)\n",
        "  if k==0:\n",
        "    ax.text(1.0, 0.9, 'train', color='y', transform=ax.transAxes)\n",
        "    ax.text(1.0, 0.65, 'test', color='m', transform=ax.transAxes)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJZwwcFO-Je"
      },
      "source": [
        "---\n",
        "# Section 2: Introduction to convolutions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TJbrubUfO-Je"
      },
      "source": [
        "#@title Video 1: Intro to convolutions\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"vPNu8CNg9i4\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOKDNYqDEtGS"
      },
      "source": [
        "# Summary of Video 1:\n",
        "\n",
        "- build\n",
        "an encoding model to try to understand\n",
        "how neurons represent\n",
        "different visual stimuli \n",
        "- network will take as input as stimulus\n",
        "and output prediction for each of\n",
        "these neurons activity \n",
        "- let's look at some of\n",
        "this neural data\n",
        "- in this case we split the\n",
        "stimuli into two sets\n",
        "train test and a test set\n",
        "then we bin the stimuli in\n",
        "bins of six degrees and average the\n",
        "responses within that bin for each given\n",
        "neuron \n",
        "- now that we've done the binning\n",
        "you can look at these different neurons\n",
        "tuning curves and\n",
        "in some cases you can see two peaks in\n",
        "response to these stimuli\n",
        "in some cases maybe you see more than\n",
        "two peaks \n",
        "\n",
        "- but in many of these cases it looks like\n",
        "these tuning curves are the sum\n",
        "of a few of these peaks at different\n",
        "locations along this\n",
        "stimulus orientation\n",
        "dimension and in fact\n",
        "a model such as this which is the sum of\n",
        "a few filters along\n",
        "a given dimension is called a\n",
        "convolutional model \n",
        "\n",
        "- going to use a\n",
        "deep network now with convolutions in\n",
        "order to fit these neural responses\n",
        "\n",
        "- convolution is the integral\n",
        "of a product of two functions one of\n",
        "which is our filter f\n",
        "and our stimulus s which in this case we've created our stimulus such that\n",
        "it's zero everywhere\n",
        "except for one in the stimulus bin where\n",
        "the stimulus\n",
        "is that orientation\n",
        "so if you want to perform a convolution\n",
        "and get the same\n",
        "output as the input you need to pad the\n",
        "input by half the filter size on each\n",
        "side\n",
        "\n",
        "- next let's compute the output of the\n",
        "convolution at each position\n",
        "x along the stimulus dimension; \n",
        "and the size of its response after\n",
        "performing this convolution is called\n",
        "its activation\n",
        "\n",
        "- so to compute a sub x we're going to\n",
        "slide this filter\n",
        "f along the stimulus s and compute the\n",
        "sum of the product at each of these\n",
        "points\n",
        "\n",
        "- another parameter of this convolution\n",
        "computation is the stride\n",
        "and the stride is how often along the\n",
        "stimulus to compute \n",
        "\n",
        "- we use a stride of\n",
        "one; we have a different unit\n",
        "for\n",
        "every single position along the stimulus\n",
        "axis x\n",
        "but we could also use a stride of 10\n",
        "where we'd have\n",
        "fewer responses that are more spread out\n",
        "here\n",
        "and this can be advantageous in terms of\n",
        "efficiency if you want to\n",
        "reduce the amount of computation that\n",
        "you have to do\n",
        "\n",
        "- so now how do we compute this\n",
        "computation\n",
        "of this convolution so we can loop over\n",
        "these positions\n",
        "with some spacing which is the stride\n",
        "and then at each of these positions x\n",
        "we're going to take the\n",
        "sum of the product of the filter and the\n",
        "stimulus\n",
        "\n",
        "- so how do we compute a convolution in pytorch?\n",
        "create a convolutional layer which\n",
        "which in this case takes as input a\n",
        "stimulus\n",
        "\n",
        "which looks like - zero\n",
        "everywhere except for one\n",
        "in the bin where the stimulus was active\n",
        "now\n",
        "this convolutional layer is initialized\n",
        "with a few different parameters \n",
        "\t- number of input channels\n",
        "and in this case it's one because we\n",
        "only have one\n",
        "stimulus dimension here and then\n",
        "\t- number of convolutional channels \n",
        "we'll set the default value to eight and then the last one is the size of the\n",
        "filter k which we set again to\n",
        "to a default value which is nine \n",
        "\n",
        "-the input channels\n",
        "=the number of output channels which is\n",
        "=the number of convolutional channels\n",
        "\n",
        "- create\n",
        "the kernel size and then also the\n",
        "padding which\n",
        "again will set to the kernel size\n",
        "over two\n",
        "and then the stride will be one so now\n",
        "input which is has a length of 60 we'll\n",
        "get an output which is also a length of\n",
        "60. \n",
        "\n",
        "- we're going to have to add the\n",
        "singleton dimension which is adding this\n",
        "one dimensional channel\n",
        "which is the cn and then after we add\n",
        "x through this convolutional layer and\n",
        "get our output\n",
        "\n",
        "- so why are convolutions good for\n",
        "encoding models; \n",
        "in fact the brain itself\n",
        "has a convolutional like architecture;\n",
        "so in the retina there are a variety of\n",
        "cell types which we can think of\n",
        "as different filters and each of these\n",
        "cells\n",
        "tile the entire visual space \n",
        "\n",
        "- in barrel cortex we have a similar\n",
        "situation where each of the whiskers\n",
        "activations\n",
        "corresponding to a\n",
        "single cortical column of activity\n",
        "and the functions computed in each of\n",
        "these columns is similar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9akKseqtO-Jf"
      },
      "source": [
        "## Section 2.1: 1d convolution in numpy\n",
        "\n",
        "We provide an example function below, described in the video, which performs a 1D convolution of a stimulus input $s$ with **filter** $f$ of size $K$ (these filters are also called *kernels*). In particular, it computes:\n",
        "\n",
        "$$a_x = \\sum^{K/2}_{i=-K/2} f_i \\, s_{x-i}$$\n",
        "\n",
        "where $a_x$ is the convolutional output at position $x$.\n",
        "\n",
        "There is no exercise in this section but make sure you understand what is happening in the function below (i.e. what a convolution is). It can be helpful to write or draw this out on paper to clarify! You could even make your own short stimulus and filter and calculate what you think the convolutional output should be by hand, and then compare to the function output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrAScu3hO-Jf"
      },
      "source": [
        "def convolve1d(stimulus, f, pad, stride):\n",
        "  \"\"\" Pads stimulus and performs 1d convolution\n",
        "\n",
        "  Args:\n",
        "    stimulus (ndarray): the 1D input for the convolution\n",
        "    f (ndarray): the 1D filter for the convolution\n",
        "    pad (scalar): the amount of zero padding for the stimulus\n",
        "    stride (scalar): how far the filter moves every step\n",
        "\n",
        "  Returns:\n",
        "    (ndarray): convolutional output, same size as stimulus\n",
        "  \"\"\"\n",
        "\n",
        "  # Pad the stimulus\n",
        "  zero_pads = np.zeros(pad)\n",
        "  padded_stimulus = np.concatenate((zero_pads, stimulus, zero_pads))\n",
        "\n",
        "  # Initialize convolutional output\n",
        "  a = np.nan * np.zeros(360)\n",
        "\n",
        "  # Compute the convolution\n",
        "  for x in np.arange(0+pad, 360+pad, stride, int): # loop over positions x\n",
        "\n",
        "    # Compute element-wise multiplication between filter and stimulus\n",
        "    a[x - pad] = (f * padded_stimulus[x-pad : x+pad]).sum()\n",
        "\n",
        "  return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "lTuKS_glO-Jg"
      },
      "source": [
        "#@title\n",
        "#@markdown Execute this cell to call convolve1d with a Gaussian filter and plot results\n",
        "\n",
        "# Convolutional parameters\n",
        "K = 49 # size of convolutional filter\n",
        "stride = 1 # how often to compute the convolution along the stim axis\n",
        "pad = K // 2 # we will need to pad stimulus with zeros to perform convolution\n",
        "\n",
        "# Create stimulus\n",
        "ori = 135\n",
        "stimulus = np.zeros(360)\n",
        "stimulus[ori] = 1.0\n",
        "\n",
        "# Create Gaussian filter\n",
        "# we will use the code from W2D1 (bayes day) to create this!\n",
        "# mean of gaussian mu=0\n",
        "i = np.arange(-pad, pad)\n",
        "f = my_gaussian(i, 0.0, sigma=10)\n",
        "\n",
        "# Call function\n",
        "a = convolve1d(stimulus, f, pad, stride)\n",
        "\n",
        "# Plot results\n",
        "fig = plt.figure(figsize=(15,4))\n",
        "plot_conv(pad, stimulus, f, a)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDmlg7ULO-Jg"
      },
      "source": [
        "## Section 2.2: Convolutional layer\n",
        "\n",
        "You have just learned how to compute what is called a single convolutional **channel**: a single filter applied to the input resulting in several units, where the number of units depends on the *stride* you set.\n",
        "\n",
        "(Note if filter size *K* is odd and you set the *pad=K//2* and *stride=1* (as is the default above), you get a **channel** of units that is the same size as the input.)\n",
        "\n",
        "*Contemplation:* How does a neuron potentially combine those activation units and create the tuning curves they have? Will we need more than one convolutional filter to recreate all the responses we see?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6uD3qKqO-Jg"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_185efdad.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbcwzOS3O-Jg"
      },
      "source": [
        "Let's add more convolutional channels and implement this operation efficiently using pytorch. A *layer* of convolutional channels can be implemented with one line of code using the PyTorch class `nn.Conv1d()`, which requires the following arguments for initialization:\n",
        "  * $C^{in}$: the number of input channels\n",
        "  * $C^{out}$: the number of output channels (number of different convolutional filters)\n",
        "  * $K$: the size of the $C^{out}$ different convolutional filters\n",
        "  \n",
        "When you run the network, you can input a stimulus of arbitrary length ($H^{in}$), but it needs to be shaped as a 2D input $C^{in} \\times H^{in}$. In our case, $C^{in}=1$ because there is only one orientation input and $H^{in}$ is the number of stimulus bins $B$.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/NeuromatchAcademy/course-content/blob/master/tutorials/static/convolutional_layer.PNG?raw=true\" width=\"600\" />\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpmIzIKmO-Jg"
      },
      "source": [
        "class ConvolutionalLayer(nn.Module):\n",
        "  \"\"\"Deep network with one convolutional layer\n",
        "     Attributes: conv (nn.Conv1d): convolutional layer\n",
        "  \"\"\"\n",
        "  def __init__(self, c_in=1, c_out=8, K=9):\n",
        "    \"\"\"Initialize layer\n",
        "\n",
        "    Args:\n",
        "        c_in: number of input stimulus channels\n",
        "        c_out: number of output convolutional channels\n",
        "        K: size of each convolutional filter\n",
        "\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv1d(c_in, c_out, kernel_size=K,\n",
        "                          padding=K//2, stride=1)\n",
        "\n",
        "  def forward(self, s):\n",
        "    \"\"\"Run stimulus through convolutional layer\n",
        "\n",
        "    Args:\n",
        "        s (torch.Tensor): n_stimuli x h tensor with stimuli\n",
        "\n",
        "    Returns:\n",
        "        (torch.Tensor): n_stimuli x c_out x h tensor with convolutional layer unit activations.\n",
        "\n",
        "    \"\"\"\n",
        "    s = s.unsqueeze(1)  # n_stimuli x 1 x h, add a singleton dimension for the single channel\n",
        "    a = self.conv(s)  # output of convolutional layer\n",
        "\n",
        "    return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COXnO_7eO-Jg"
      },
      "source": [
        "### Exercise 1: 1D convolution in pytorch \n",
        "\n",
        "We will now run the convolutional layer on our stimulus. In particular, we will use the binary stimuli (`stim_binary`), which is a 60 x 60 tensor where each row contains the binary stimuli for one orientation (all zeros except for a one at that orientation). This tensor is size 60 instead of 360 because we have binned the orientations. Each row of this matrix is a different example orientation that we want to convolve - see cell below to visualize three rows of this tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "pct5grDmO-Jh"
      },
      "source": [
        "# @markdown Execute this cell to visualize stim_binary\n",
        "row_inds = [10, 25, 40]\n",
        "fig = plt.figure(figsize=(15,4))\n",
        "\n",
        "for j, row_ind in enumerate(row_inds):\n",
        "  ax = fig.add_subplot(1, 3, j+1)\n",
        "  ax.plot(np.arange(0, 60), stim_binary[row_ind,:], 'k')\n",
        "  ax.set_title('stim_binary row '+str(row_ind))\n",
        "  ax.set_xlabel('orientation bin')\n",
        "  ax.set_ylabel('stimulus')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCDbu-8xO-Jh"
      },
      "source": [
        "`nn.Conv1d` takes in a tensor of size $(N, C^{in}, H^{in}$) where $N$ is the number of examples, $C^{in}$ is the number of input channels, and $H^{in}$ is the number of stimulus bins $B$. Since our stimulus has only one input channel,  the `ConvolutionalLayer` class adds the $C^{in}$ dimension for us: we need to input an $(N, H^{in})$ stimulus, which `stim_binary` is!  \n",
        "\n",
        "\n",
        "We will plot the outputs of the convolution. `convout` is a tensor of size $(N, C^{out}, H^{in})$ where $N$ is the number of examples and $C^{out}$ are the number of convolutional channels. In the plot, the activations for a single channel are shown in one color. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPGt1CBNO-Ji"
      },
      "source": [
        "# Convolution layer parameters\n",
        "K = 9 # filter size, now that we've binned let's make this smaller than for the numpy conv\n",
        "conv_channels = 8 # how many convolutional channels to have in our layer\n",
        "\n",
        "convout = np.zeros(0) # assign convolutional activations to convout\n",
        "\n",
        "################################################################################\n",
        "## TODO for students: compute convolution activations from stim_binary using pytorch\n",
        "# Complete and uncomment\n",
        "################################################################################\n",
        "\n",
        "# Initialize conv layer\n",
        "# convLayer = ConvolutionalLayer(...)\n",
        "\n",
        "# Call conv layer on stimulus\n",
        "# convout = convLayer(...)\n",
        "# convout = convout.detach() # detach gradients\n",
        "# print(convout.shape) # can you identify what each of these dimensions are?\n",
        "\n",
        "# Plot results\n",
        "# plot_example_activations(convout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "158c9b20-a905-4e1b-eb11-16b898d4454c",
        "id": "86UeaN39O-Ji"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_44e9267a.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=851 height=270 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D4_DeepLearning1/static/W3D4_Tutorial2_Solution_44e9267a_1.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Pe0ZALO-Ji"
      },
      "source": [
        "#### Think!\n",
        "  - Why are the convolutional activations for a given channel the same for many units?\n",
        "  - What is the width of the non-constant activations (i.e. how many units in a given channel would differ from the constant)?\n",
        "  - How many weights does this convLayer have? \n",
        "  - How many would it have if it were a fully connected layer? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKTRE1uoO-Ji"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_32703d8b.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX4aNR6aO-Jj"
      },
      "source": [
        "---\n",
        "# Section 3: Encoding model using convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EdbFUeCcO-Jj"
      },
      "source": [
        "#@title Video 2: Encoding model using convolutions\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"Me8X3Kro0EE\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltnupd9IGUwK"
      },
      "source": [
        "# Summary of Video 2:\n",
        "\n",
        "- let's build our convolutional encoding model.\n",
        "- put these\n",
        "convolutions together with a fully connected layer and create an encoding model.\n",
        "We input the stimulus which in this case has a dimensionality V and\n",
        "we use a filter size of K\n",
        "where K is 3 so it has three weights. And so now in this layer of\n",
        "this network where we have this first channel of our convolutional layer,\n",
        "we're going to compute the\n",
        "activations. \n",
        "\n",
        "- eg: take S 2,\n",
        "multiply it by W 1 1 and add that to as 3\n",
        "times W 1 2 and add that to S 4 times W 1 3. And\n",
        "then we can do this for a second unit\n",
        "where we compute the multiplication of these \n",
        "inputs with these weights and we get our activation\n",
        "H14. And then we can do the same thing when we add a second channel of weights\n",
        "where we multiply these\n",
        " stimulus inputs by these weights\n",
        "\n",
        "- for both these cases and we slide these down to compute our hidden unit activations. So\n",
        "we get our hidden layer H is going to be W in,\n",
        "which in this case are these weights for these different channels, convolved with our stimulus S,\n",
        "plus some bias term B.  C out is a number of convolutional channels we have which in this case is 2, and so\n",
        "the number of hidden units we have in total is going to be the number of convolutional channels we have\n",
        "times the number of\n",
        "stimulus bins we have, B, because we're using the same padding, so we get the same size\n",
        "output as we give input.\n",
        "\n",
        "- If this were a fully connected layer like the linear layers \n",
        "how many parameters would W have?\n",
        "We have an input size B and we have B times C out\n",
        "unit. So we had a fully connected linear layer. We would have B times B times C out\n",
        "number of weights.\n",
        "\n",
        "- So on the other hand in this convolutional layer, how many weights do we have? We have\n",
        "K weights for each of our channels. So we have K times C out ways.\n",
        "\n",
        "- And in most cases the number of parameters you need for the linear layer is much greater and it becomes even\n",
        "substantially greater as the\n",
        "dimensionality of your stimulus increases because the number of weights you need is B times B times C out which is B squared.\n",
        "So now we found that using these convolutional models allows us to reduce the number of weights we need,\n",
        "let's use these convolutional models to predict our neural responses. So we need to add to this convolutional layer - a fully connected layer\n",
        "which we'll call the weights of this layer W out, and Y, which is our neural prediction, will be W out times H\n",
        "plus B out.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo9Ft3FDO-Jj"
      },
      "source": [
        "## Section 3.1: Convolutional layer & fully connected layer\n",
        "\n",
        "We will now build an encoding model by hooking this convolutional layer up to a fully connected layer, like the one that we used in Tutorial 1 (`nn.Linear`). We will use this model to predict neural responses.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/NeuromatchAcademy/course-content/blob/master/tutorials/static/conv_fc.PNG?raw=true\" width=\"800\" />\n",
        "</p>\n",
        "\n",
        "This linear layer will have weights $W^{out}$ and we will get an output vector $\\mathbf{y}$ of predicted neural responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBmhGfMTO-Jk"
      },
      "source": [
        "### Exercise 2: Implement encoding model \n",
        "\n",
        "In this exercise, you will create the encoding model described above. In particular, you will:\n",
        "\n",
        "* Add a fully connected layer to `__init__` method of network.\n",
        "* Add a fully connected layer to `forward` method of network.\n",
        "\n",
        "We will then train the network using the helper function `train`. Full training will take a few minutes: if you want to train for just a few steps to speed up the code while iterating on your code, you can decrease the `n_iter` input from 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln6lCGZ0O-Jk"
      },
      "source": [
        "class ConvFC(nn.Module):\n",
        "  \"\"\"Deep network with one convolutional layer + one fully connected layer\n",
        "\n",
        "  Attributes:\n",
        "    conv (nn.Conv1d): convolutional layer\n",
        "    dims (tuple): shape of convolutional layer output\n",
        "    out_layer (nn.Linear): linear layer\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, n_neurons, c_in=1, c_out=8, K=9, b=60):\n",
        "    \"\"\" initialize layer\n",
        "    Args:\n",
        "        c_in: number of input stimulus channels\n",
        "        c_out: number of convolutional channels\n",
        "        K: size of each convolutional filter\n",
        "        h: number of stimulus bins, n_bins\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv1d(c_in, c_out, kernel_size=K, padding=K//2)\n",
        "    self.dims = (c_out, b)  # dimensions of conv layer output\n",
        "    M = np.prod(self.dims) # number of hidden units\n",
        "\n",
        "    ################################################################################\n",
        "    ## TO DO for students: add fully connected layer to network (self.out_layer)\n",
        "    # Fill out function and remove\n",
        "    raise NotImplementedError(\"Student exercise: add fully connected layer to initialize network\")\n",
        "    ################################################################################\n",
        "    self.out_layer = nn.Linear(M, ...)\n",
        "\n",
        "    nn.init.normal_(self.out_layer.weight, std=0.01) # initialize weights to be small\n",
        "\n",
        "  def forward(self, s):\n",
        "    \"\"\" Predict neural responses to stimuli s\n",
        "\n",
        "    Args:\n",
        "        s (torch.Tensor): p x L tensor with stimuli\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: p x N tensor with convolutional layer unit activations.\n",
        "\n",
        "    \"\"\"\n",
        "    s = s.unsqueeze(1)  # p x 1 x L, add a singleton dimension for the single channel\n",
        "    a = self.conv(s)  # output of convolutional layer\n",
        "    a = a.view(-1, np.prod(self.dims))  # flatten each convolutional layer output into a vector\n",
        "\n",
        "    ################################################################################\n",
        "    ## TO DO for students: add fully connected layer to forward pass of network (self.out_layer)\n",
        "    # Fill out function and remove\n",
        "    raise NotImplementedError(\"Student exercise: add fully connected layer to network\")\n",
        "    ################################################################################\n",
        "    y = ...\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "# Choose loss function\n",
        "MSE_loss = nn.MSELoss()\n",
        "\n",
        "## Initialize network\n",
        "# net = ConvFC(n_neurons)\n",
        "\n",
        "## Run GD on training set data\n",
        "## ** this time we are also providing the test data to estimate the test loss\n",
        "# train_loss, test_loss = train(net, MSE_loss, stim_binary, resp_train,\n",
        "#                               test_data=stim_binary, test_labels=resp_test,\n",
        "#                               n_iter=500, learning_rate=20)\n",
        "\n",
        "## Plot the training loss over iterations of GD\n",
        "# plot_training_curves(train_loss, test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "f2e0daf0-ae57-45b9-c82a-6ce98087a5e4",
        "id": "Kvuo66Z2O-Jl"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_fda4c007.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=558 height=414 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D4_DeepLearning1/static/W3D4_Tutorial2_Solution_fda4c007_11.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT5fhV7YO-Jl"
      },
      "source": [
        "We trained this network to predict the neural responses -- see the yellow curve for the training loss. We also computed the test loss every 50 iterations. The training loss goes down throughout training but the testing loss doesnt -- why is this? *We are overfitting to the NOISE in the training set.*\n",
        "\n",
        "Lets look at a prediction for a single neuron (below). The yellow curve is the training data, the pink curve is the testing data and the prediction is in green. You can barely see the yellow curve because the prediction has fit so well to the training data. However, some of what it has fit is noise. \n",
        "\n",
        "If we look at the weight matrix, we see that the weights are all positive or negative. Did we expect this to happen? Or did we think that this tuning curve is the sum of only a few filters and positions?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rAOlyK6O-Jm"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_5d5c2c4f.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6iCyHOV-O-Jm"
      },
      "source": [
        "#@title\n",
        "#@markdown Execute this cell to examine prediction for example neuron and see weights\n",
        "\n",
        "# Input stimuli to network\n",
        "y_pred = net(stim_binary)\n",
        "print('output shape: ', y_pred.shape) # what are the two dimensions of this network output?\n",
        "\n",
        "# Plot example neural response prediction and some fully-connected layer weights\n",
        "\n",
        "# Look at the weights of the out_layer of the network\n",
        "weights = net.out_layer.weight.detach()\n",
        "print('output weights shape: ', weights.shape) # what are these two dimensions of the fully connected layer weights?\n",
        "\n",
        "# Plot prediction + neuron + weights\n",
        "neuron_index = np.random.choice(n_neurons)\n",
        "plot_pred_weights(y_pred[:,neuron_index].detach(), resp_train[:,neuron_index],\n",
        "                  resp_test[:,neuron_index], weights[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShCeJvNxO-Jn"
      },
      "source": [
        "*Comprehension check*: what does each dimension of the output and output weights correspond to?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJBEErTsO-Jn"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_fa083d69.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xIM-gE6O-Jn"
      },
      "source": [
        "We can reduce overfitting using L2 regularization as we learned on W1D4. \n",
        "\n",
        "Additionally there is another type of regularization you might want... If we think of a neuron as a sum of a few convolutional filters, we might expect the weight matrix of the fully-connected layer to be sparse. Therefore, we can also apply an L1 regularization penalty to enforce sparsity. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3QQNzo-O-Jn"
      },
      "source": [
        "---\n",
        "# (Bonus) Section 4: Regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "2o5Qh51HO-Jn"
      },
      "source": [
        "#@title Video 3: Regularization\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"Qnn5OPHKo5w\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY1dBzAXHwmD"
      },
      "source": [
        "# Summary of Video 3:\n",
        "\n",
        "- We can also use regularization in deep networks to reduce overfitting\n",
        "and in particular it's especially important in deep networks because deep networks can have millions of parameters.\n",
        "\n",
        "- as a function of the number of operations that they perform vs as a function of their performance on imagenet.\n",
        "=> each of these different networks is proportional to the number of parameters\n",
        "that each of these networks has.\n",
        "\n",
        "- You can use L1 and L2 regularization.\n",
        "You can also use a technique called batch\n",
        "normalization and this helps to keep your activations at a similar size and distribution across layers to improve optimization.\n",
        "It's especially important if you have very deep networks.\n",
        "We can also\n",
        "use a technique called dropout which randomly removes units from the network during training\n",
        "but this approach is not used so often anymore.\n",
        "\n",
        "- And then finally, you can just reduce the number of parameters by using techniques like using convolutions. \n",
        "\n",
        "- So, how does L2 regularization work? So we have a cost function\n",
        " which is going to be our squared error loss term plus an additional term\n",
        "which is a penalty on the norm of the weights.\n",
        "And this prevents the weights from being large and potentially just being large to fit some noisy aspects of the training data.\n",
        "So if we differentiate this cost function\n",
        "we get the the first term which is our usual gradient of the loss function with respect to our weight W,\n",
        "plus a a term that's two times lambda times the sum of the weights.\n",
        "So for a given weight the update is going to be subtracting our original loss\n",
        "gradient here,\n",
        "plus subtracting the\n",
        "term that's proportional to the weight itself.\n",
        "\n",
        "- And so if the weight is positive you're going to subtract a positive value and push this weight towards zero.\n",
        "Likewise if the weight is negative you're going to be subtracting a negative value, which is addition,\n",
        "so you're going to be pushing that weight up so whether you're positive or negative\n",
        "these weights are going to get shrunk to zero and that's why this type of regularization is called weight decay.\n",
        "\n",
        "- And you can implement this in your optimizer\n",
        "using weight decay parameter as an input, or you can opt you can\n",
        "add it to your network manually\n",
        "which is what we do in this case where we take the weights of our linear layer and we add this L2 penalty,\n",
        "which is going to be squaring the weights and then summing them.\n",
        "\n",
        "- L1 regularization adds a penalty which is the sum of the absolute value of the weights\n",
        "and now this results in an update rule that only depends on the sign of the weight itself.\n",
        "So this is going to be\n",
        "larger than the weight decay penalty usually,\n",
        "And it's only going to be zero when the weight is set to zero. Otherwise, it's going to be plus one or minus one.\n",
        "So this means that L1 produces more sparse solutions, which in the case of the encoding models is useful because it's easier \n",
        "to interpret these models when they only have a few positive weights such as they're only adding a few different convolutional filters.\n",
        "However, it can often be harder to optimize these types of functions.\n",
        "\n",
        "- So L1 is producing these more sparse solutions where fewer weights are non-zero\n",
        "whereas L2 is reducing the size of these weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC18Ah-1O-Jn"
      },
      "source": [
        "\n",
        "As discussed in the lecture, it is often important to incorporate regularization terms into the loss function to avoid overfitting. In particular, in this case, we want to use these terms to enforce sparsity in the output layer. \n",
        "\n",
        "Here we'll consider the classic L2 regularization penalty $\\mathcal{R}_{L2}$, which is the sum of squares of each weight in the network $\\sum_{ij} {\\mathbf{W}^{out}_{ij}}^2$ times a constant that we call `L2_penalty`.\n",
        "\n",
        "We will also add an L1 regularization penalty $\\mathcal{R}_{L1}$ to enforce sparsity of the weights, which is the sum of the absolute values of the weights $\\sum_{ij} |{\\mathbf{W}^{out}_{ij}}|$ times a constant that we call `L1_penalty`.\n",
        "\n",
        "We will add both of these to the loss function:\n",
        "\\begin{equation}\n",
        "    L = (y - \\tilde{y})^2 + \\mathcal{R}_{L2} + \\mathcal{R}_{L1}\n",
        "\\end{equation}\n",
        "\n",
        "The parameters `L2_penalty` and `L1_penalty` are inputs to the train function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk3VdUoQO-Jo"
      },
      "source": [
        "### (Bonus) Exercise 3: Add regularization to training \n",
        "\n",
        "We will create a new loss function that adds L1 and L2 regularization. \n",
        "In particular, you will:\n",
        "* add L2 loss penalty to the weights \n",
        "* add L1 loss penalty to the weights\n",
        "\n",
        "\n",
        "We will then train the network using this loss function. Full training will take a few minutes: if you want to train for just a few steps to speed up the code while iterating on your code, you can decrease the n_iter input from 500. \n",
        "\n",
        "Hint: since we are using `torch` instead of `np`, we will use `torch.abs` instead of `np.absolute`. You can use `torch.sum` or `.sum()` to sum over a tensor.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS9IxNe1O-Jo"
      },
      "source": [
        "def regularized_MSE_loss(output, target, weights=None, L2_penalty=0, L1_penalty=0):\n",
        "  \"\"\"loss function for MSE\n",
        "\n",
        "  Args:\n",
        "    output (torch.Tensor): output of network\n",
        "    target (torch.Tensor): neural response network is trying to predict\n",
        "    weights (torch.Tensor): fully-connected layer weights (net.out_layer.weight)\n",
        "    L2_penalty : scaling factor of sum of squared weights\n",
        "    L1_penalty : scalaing factor for sum of absolute weights\n",
        "\n",
        "  Returns:\n",
        "    (torch.Tensor) mean-squared error with L1 and L2 penalties added\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss = loss_fn(output, target)\n",
        "\n",
        "  ##############################################################################\n",
        "  # TO DO: add L1 and L2 regularization to the loss function and remove the error\n",
        "  raise NotImplementedError(\"Student exercise: complete regularized_MSE_loss\")\n",
        "  ##############################################################################\n",
        "\n",
        "  if weights is not None:\n",
        "    L2 = L2_penalty * ...\n",
        "    L1 = L1_penalty * ...\n",
        "    loss += L1 + L2\n",
        "\n",
        "  return loss\n",
        "\n",
        "# Initialize network\n",
        "net = ConvFC(n_neurons)\n",
        "\n",
        "# Uncomment below to test your function\n",
        "\n",
        "# Train network\n",
        "# train_loss, test_loss = train(net, regularized_MSE_loss, stim_binary, resp_train,\n",
        "#                               test_data=stim_binary, test_labels=resp_test,\n",
        "#                               learning_rate=10, n_iter=500,\n",
        "#                               L2_penalty=1e-4, L1_penalty=1e-6)\n",
        "\n",
        "# Plot the training loss over iterations of GD\n",
        "# plot_training_curves(train_loss, test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "d525e1c6-2d68-4315-9566-1daff87c96ca",
        "id": "eWEktx5qO-Jo"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_c4027856.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=558 height=413 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D4_DeepLearning1/static/W3D4_Tutorial2_Solution_c4027856_11.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn7wOhscO-Jp"
      },
      "source": [
        "If we now train the network with these regularization penalties we find that the train and test loss are similar throughout training: both continue decreasing.\n",
        "\n",
        "We will now look at the predictions after using the regularized loss function. We can see below that the prediction is much smoother than before! This is because the weight matrix is in fact sparser (zero is represented by white in this color map)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jGxiD7Z2O-Jp"
      },
      "source": [
        "#@title\n",
        "#@markdown Execute this cell to examine prediction for example neuron and see weights\n",
        "\n",
        "# Plot prediction + neuron + weights\n",
        "weights = net.out_layer.weight.detach()\n",
        "y_pred = net(stim_binary)\n",
        "neuron_index = np.random.choice(n_neurons)\n",
        "plot_pred_weights(y_pred[:,neuron_index].detach(), resp_train[:,neuron_index],\n",
        "                  resp_test[:,neuron_index], weights[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBt_ygLlO-Jp"
      },
      "source": [
        "\n",
        "Now let's look at what the predictions look like for many neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "V6jKZF6-O-Jp"
      },
      "source": [
        "#@title\n",
        "#@markdown Execute this cell to examine predictions for random subsets of neurons\n",
        "\n",
        "# Visualize tuning curves & plot neural predictions\n",
        "fig, axs = plt.subplots(2, 5, figsize=(15,6))\n",
        "for k, ax in enumerate(axs.flatten()):\n",
        "  ineur = np.random.choice(n_neurons)\n",
        "  plot_prediction(ax, y_pred[:,ineur].detach(), resp_test[:,ineur])\n",
        "  if k==0:\n",
        "    ax.text(.1, 1., 'test', color='m', transform=ax.transAxes)\n",
        "    ax.text(.1, .9, 'prediction', color='g', transform=ax.transAxes)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1J3Zb9QO-Jp"
      },
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "In this notebook, we built and evaluated a neural network based encoding model to predict neural responses from stimuli. To do so we :\n",
        "* implemented a basic convolution filter\n",
        "* implemented and trained a convolutional neural network with multiple filters to predict neural responses using PyTorch\n",
        "* learned about and implemented L2/L1 regularization to avoid overfitting\n",
        "\n",
        "What can this tell us about the representation of oriented gratings in mouse visual cortex? Maybe we can think of interpreting each of the convolutional channels as a computation performed by a single group of neurons in thalamus, and each visual cortical neuron combines various groups of thalamic neurons. But we'd have to test hypotheses like these by, for instance, recording thalamic neurons.\n",
        "\n",
        "\n",
        "Tutorial 3 is bonus, although we recommend watching the videos if possible!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4pYR62bO-Jq"
      },
      "source": [
        "---\n",
        "# Appendix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KhxkBvnAO-Jq"
      },
      "source": [
        "#@title Video 4: Some practical advice for fitting neural networks\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"eU74NFroIHk\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "696_TEl1K63r"
      },
      "source": [
        "# Summary of Video 4:\n",
        "\n",
        "- You should always start off by training your neural network with only a few iterations,\n",
        "and watching that progress before you let it run for hours and hours,\n",
        "While you're watching this early progress, you can change various parameters in your training.\n",
        "1. So you can add momentum (can be very helpful for optimization).\n",
        "2. You can also vary the size of the random weights at initialization.\n",
        "You can change the size of those weights and see how it potentially changes how well you can decrease\n",
        "your L1 penalty - the sparsity penalty.\n",
        "3. When you're trying to find the optimal learning rate,\n",
        "\t-an easy way to do it is to try to increase the learning rate as much as possible until the network explodes.\n",
        "Then decrease it after that and just stay as close to that explosion point as possible\n",
        "so that your learning rate is large and you're exploring a lot of the parameter space but not exploding.\n",
        "\t- Also other things people do as they can it they anneal the learning rate up at the beginning,\n",
        "starting with a small learning rate and annealing up the first few epochs,\n",
        "and then also you can anneal the learning rate down at the end, making it smaller as the epochs go on.\n",
        "4. You can also decrease potentially the batch size\n",
        "when you're running through the deep network.\n",
        "5. You can look up more about stochastic gradient descent rather than gradient descent\n",
        "which is particularly important when you have a really large data set. You can't run all those images at the same time. So you use batches.\n",
        "\n",
        "myths:\n",
        "1. Some people say bigger networks overfit more.\n",
        "That can depend a lot on the architecture and whether or not you have for instance skip connections\n",
        "or you're using residual networks.\n",
        "2. Some people think that certain optimizers perform better like Adam or Adagrad.\n",
        "You can try these different optimizers and see if they work better or worse for your specific problem.\n",
        "3. People also say that stopping the optimization early is important.\n",
        "And so that might be because you don't want to overfit too much to your test data.\n",
        "But hopefully you have enough regularization in your network that that's not a problem.\n",
        "4. Your test and your training loss decrease somewhat similarly across iterations.\n",
        "In the past people often used dropout,\n",
        "but it tends to be the case that batch normalization will work better for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AjHKQGmO-Jr"
      },
      "source": [
        "## Why CNN's?\n",
        "\n",
        "CNN models are particularly [well-suited](https://www.nature.com/articles/nn.4244) to modeling the visual system for a number of reasons:\n",
        "\n",
        "1. **Distributed computation**: like any other neural network, CNN's use distributed representations to compute -- much like the brain seems to do. Such models, therefore, provide us with a vocabulary with which to talk and think about such distributed representations. Because we know the exact function the model is built to perform (e.g. orientation discrimination), we can analyze its internal representations with respect to this function and begin to interpret why the representations look the way they do. Most importantly, we can then use these insights to analyze the structure of neural representations observed in recorded population activity. We can qualitatively and quantitatively compare the representations we see in the model and in a given population of real neurons to hopefully tease out the computations it performs.\n",
        "\n",
        "2. **Hierarchical architecture**: like in any other deep learning architecture, each layer of a deep CNN comprises a non-linear transformation of the previous layer. Thus, there is a natural hierarchy whereby layers closer to the network output represent increasingly more abstract information about the input image. For example, in a network trained to do object recognition, the early layers might represent information about edges in the image, whereas later layers closer to the output might represent various object categories. This resembles the [hierarchical structure of the visual system](https://pubmed.ncbi.nlm.nih.gov/1822724/), where [lower-level areas](https://www.jneurosci.org/content/25/46/10577.short) (e.g. retina, V1) represent visual features of the sensory input and [higher-level areas](https://www.sciencedirect.com/science/article/pii/S089662731200092X) (e.g. V4, IT) represent properties of objects in the visual scene. We can then naturally use a single CNN to model multiple visual areas, using early CNN layers to model lower-level visual areas and late CNN layers to model higher-level visual areas.\n",
        "  \n",
        "  Relative to fully connected networks, CNN's, in fact, have further hierarchical structure built-in through the max pooling layers. Recall that each output of a convolution + pooling block is the result of processing a local patch of the inputs to that block. If we stack such blocks in a sequence, then the outputs of each block will be sensitive to increasingly larger regions of the initial raw input to the network: an output from the first block is sensitive to a single patch of these inputs, corresponding to its \"receptive field\"; an output from the second block is sensitive to a patch of outputs from the first block, which together are sensitive to a larger patch of raw inputs comprising the union of their receptive fields. Receptive fields thus get larger for deeper layers (see [here](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/) for a nice visual depiction of this). This resembles primate visual systems, where neurons in higher-level visual areas respond to stimuli in wider regions of the visual field than neurons in lower-level visual areas.\n",
        "\n",
        "3. **Convolutional layers**: through the weight sharing constraint, the outputs of each channel of a convolutional layer process different parts of the input image in exactly the same way. This architectural constraint effectively builds into the network the assumption that objects in the world typically look the same regardless of where they are in space. This is useful for modeling the visual system for two (largely separate) reasons:\n",
        "  * Firstly, this assumption is generally valid in mammalian visual systems, since mammals tend to view the same object from many perspectives. Two neurons at a similar hierarchy in the visual system with different receptive fields could thus end up receiving statistically similar synaptic inputs, so that the synaptic weights developed over time may end up being similar as well.\n",
        "  * Secondly, this architecture significantly improves object recognition ability. Object recognition was essentially an unsolved problem in machine learning until the [advent](https://en.wikipedia.org/wiki/AlexNet) of techniques for effectively training *deep* convolutional neural networks. Fully connected networks on their own can't achieve object recognition abilities anywhere close to human levels, making them bad models of human object recognition. Indeed, it is generally the case that [the better a neural network model is at object recognition, the closer the match between its representations and those observed in the brain](https://www.pnas.org/content/111/23/8619.short). That said, it is worth noting that our much simpler orientation discrimination task (in Tutorial 3) can be solved by relatively simple networks."
      ]
    }
  ]
}